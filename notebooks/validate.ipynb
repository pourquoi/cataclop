{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cataclop.ml import preprocessing\n",
    "from cataclop.ml import exploration\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from cataclop.ml.pipeline import factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = factories.Program.factory('2019-01-24', version='1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing model data\n",
      "preparing stacked model data\n"
     ]
    }
   ],
   "source": [
    "program.predict(dataset_params = {\n",
    "    'from': '2018-12-01',\n",
    "    'to': '2018-12-10'\n",
    "}, locked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(program.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = program.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bet(df, features, categorical_features, targets, N=1, max_odds=20, break_on_bet=True, break_on_odds=False):\n",
    "\n",
    "    races = df.sort_values('start_at').groupby('race_id')\n",
    "\n",
    "    bets = []\n",
    "\n",
    "    for (id, race) in races:\n",
    "\n",
    "        candidate_bets = []\n",
    "\n",
    "        nums = []\n",
    "\n",
    "        for target in targets:\n",
    "\n",
    "            r = race.sort_values(by=target, ascending=False)\n",
    "\n",
    "            if len(r) <= N:\n",
    "                break\n",
    "                \n",
    "            NN = N\n",
    "\n",
    "            for n in range(NN):\n",
    "\n",
    "                player = r.iloc[n]\n",
    "\n",
    "                odds = player['final_odds_ref']\n",
    "\n",
    "                if max_odds is not None and odds > max_odds:\n",
    "                    if break_on_odds:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                nth = (r['final_odds_ref']<odds).sum()+1\n",
    "                \n",
    "                #bet = np.clip(np.abs(player[target])/100.0, 0, 10)\n",
    "                \n",
    "                #bet = np.round(1+bet) * 1.5\n",
    "                \n",
    "                #if bet <= 0:\n",
    "                #    break\n",
    "                \n",
    "                if n+1 < len(r) and r.iloc[n+1][target] == player[target]:\n",
    "                    NN = NN+1\n",
    "                    \n",
    "                bet = 1\n",
    "                \n",
    "                wd = player['final_odds_ref_unibet'] if player['final_odds_ref_unibet'] > player['final_odds_ref'] else player['winner_dividend']\n",
    "\n",
    "                profit = wd/100.0 * bet - bet\n",
    "                profit_placed = player['placed_dividend']/100.0 * bet - bet\n",
    "\n",
    "                row = [id, player['start_at'], player['num'], player['position'], n, odds, player['final_odds_ref_unibet'], player['final_odds'], target, player[target], r[target].std(), bet, profit, profit_placed]\n",
    "\n",
    "                for nn in range(1,4):\n",
    "                    if n+nn < len(r):\n",
    "                        row.append(r.iloc[n+nn][target])\n",
    "                    else:\n",
    "                        row.append(np.nan)\n",
    "\n",
    "                for f in features:\n",
    "                    row.append(player[f])\n",
    "                for f in categorical_features:\n",
    "                    row.append(player[f])\n",
    "                    \n",
    "\n",
    "                candidate_bets.append( row )\n",
    "\n",
    "                nums.append(player['num'])\n",
    "\n",
    "                if break_on_bet:\n",
    "                    break\n",
    "\n",
    "        #if len(candidate_bets) == 1:\n",
    "        #    bets += candidate_bets\n",
    "        bets += candidate_bets\n",
    "\n",
    "    cols = ['id', 'date', 'num', 'pos', 'nb', 'odds_ref', 'odds_unibet', 'odds_final', 'target', 'pred', 'pred_std', 'bet', 'profit', 'profit_placed']\n",
    "\n",
    "    for nn in range(1,4):\n",
    "        cols.append('next_pred_{}'.format(nn))\n",
    "\n",
    "    cols = cols + features + categorical_features\n",
    "\n",
    "    bets = pd.DataFrame(bets, columns=cols)\n",
    "    bets['date'] = pd.to_datetime(bets['date'])\n",
    "\n",
    "    bets = bets.set_index(bets['date'])\n",
    "    bets = bets.sort_index()\n",
    "\n",
    "    bets['bets'] = bets['bet'].cumsum()\n",
    "    bets['stash'] = bets['profit'].cumsum()\n",
    "\n",
    "    return bets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>declared_player_count</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>num</th>\n",
       "      <th>final_odds</th>\n",
       "      <th>final_odds_unibet</th>\n",
       "      <th>target_pos</th>\n",
       "      <th>pred_xgb_100_1</th>\n",
       "      <th>pred_xgb_10_1</th>\n",
       "      <th>pred_xgb_30_1</th>\n",
       "      <th>pred_xgb_100_1</th>\n",
       "      <th>pred_knn_1_1</th>\n",
       "      <th>pred_knn_2_1</th>\n",
       "      <th>pred_knn_3_1</th>\n",
       "      <th>pred_knn_4_1</th>\n",
       "      <th>pred_knn_5_1</th>\n",
       "      <th>pred_knn_6_1</th>\n",
       "      <th>pred_knn_7_1</th>\n",
       "      <th>pred_knn_8_1</th>\n",
       "      <th>pred_knn_9_1</th>\n",
       "      <th>pred_knn_10_1</th>\n",
       "      <th>pred_stacked_mlp_relu_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">52996</th>\n",
       "      <th>455</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>10</td>\n",
       "      <td>13.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112295</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>0.105519</td>\n",
       "      <td>0.112295</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.634349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156340</td>\n",
       "      <td>0.141711</td>\n",
       "      <td>0.150699</td>\n",
       "      <td>0.156340</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.658501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>6</td>\n",
       "      <td>79.3</td>\n",
       "      <td>42.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093804</td>\n",
       "      <td>0.127808</td>\n",
       "      <td>0.103890</td>\n",
       "      <td>0.093804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.320236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>8</td>\n",
       "      <td>26.9</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>0.116812</td>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.624956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>11</td>\n",
       "      <td>29.2</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120429</td>\n",
       "      <td>0.116812</td>\n",
       "      <td>0.102376</td>\n",
       "      <td>0.120429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.638677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>6.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>2</td>\n",
       "      <td>81.6</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098492</td>\n",
       "      <td>0.114237</td>\n",
       "      <td>0.106649</td>\n",
       "      <td>0.098492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.274401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>9</td>\n",
       "      <td>83.2</td>\n",
       "      <td>76.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095572</td>\n",
       "      <td>0.116812</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>0.095572</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.660601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.135265</td>\n",
       "      <td>0.125472</td>\n",
       "      <td>0.138468</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.630397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106076</td>\n",
       "      <td>0.135265</td>\n",
       "      <td>0.113685</td>\n",
       "      <td>0.106076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.575784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106101</td>\n",
       "      <td>0.114237</td>\n",
       "      <td>0.104895</td>\n",
       "      <td>0.106101</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.616048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOSTART</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>0.133349</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>2.594701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             position  declared_player_count sub_category  num  final_odds  \\\n",
       "race_id                                                                      \n",
       "52996   455       1.0                     11    AUTOSTART   10        13.7   \n",
       "        452       2.0                     11    AUTOSTART    7         3.0   \n",
       "        451       3.0                     11    AUTOSTART    6        79.3   \n",
       "        453       4.0                     11    AUTOSTART    8        26.9   \n",
       "        456       5.0                     11    AUTOSTART   11        29.2   \n",
       "        447       6.0                     11    AUTOSTART    2        81.6   \n",
       "        454       7.0                     11    AUTOSTART    9        83.2   \n",
       "        449       8.0                     11    AUTOSTART    4         2.6   \n",
       "        448       9.0                     11    AUTOSTART    3         5.2   \n",
       "        450      10.0                     11    AUTOSTART    5        11.8   \n",
       "        446       NaN                     11    AUTOSTART    1         1.5   \n",
       "\n",
       "             final_odds_unibet  target_pos  pred_xgb_100_1  pred_xgb_10_1  \\\n",
       "race_id                                                                     \n",
       "52996   455               19.8           0        0.112295       0.130408   \n",
       "        452                2.8           0        0.156340       0.141711   \n",
       "        451               42.4           0        0.093804       0.127808   \n",
       "        453               19.3           0        0.108361       0.116812   \n",
       "        456               45.3           0        0.120429       0.116812   \n",
       "        447               37.5           0        0.098492       0.114237   \n",
       "        454               76.2           0        0.095572       0.116812   \n",
       "        449                2.2           0        0.138468       0.135265   \n",
       "        448                7.0           0        0.106076       0.135265   \n",
       "        450               11.7           0        0.106101       0.114237   \n",
       "        446                NaN           0        0.068755       0.133349   \n",
       "\n",
       "             pred_xgb_30_1  pred_xgb_100_1  pred_knn_1_1  pred_knn_2_1  \\\n",
       "race_id                                                                  \n",
       "52996   455       0.105519        0.112295      0.333333      0.166667   \n",
       "        452       0.150699        0.156340      0.333333      0.166667   \n",
       "        451       0.103890        0.093804      0.000000      0.166667   \n",
       "        453       0.101308        0.108361      0.000000      0.166667   \n",
       "        456       0.102376        0.120429      0.000000      0.166667   \n",
       "        447       0.106649        0.098492      0.000000      0.000000   \n",
       "        454       0.090607        0.095572      0.333333      0.333333   \n",
       "        449       0.125472        0.138468      0.333333      0.166667   \n",
       "        448       0.113685        0.106076      0.000000      0.166667   \n",
       "        450       0.104895        0.106101      0.333333      0.166667   \n",
       "        446       0.098890        0.068755      0.333333      0.166667   \n",
       "\n",
       "             pred_knn_3_1  pred_knn_4_1  pred_knn_5_1  pred_knn_6_1  \\\n",
       "race_id                                                               \n",
       "52996   455      0.111111      0.083333      0.066667      0.111111   \n",
       "        452      0.111111      0.166667      0.133333      0.166667   \n",
       "        451      0.111111      0.166667      0.133333      0.166667   \n",
       "        453      0.222222      0.166667      0.133333      0.111111   \n",
       "        456      0.111111      0.166667      0.133333      0.111111   \n",
       "        447      0.111111      0.166667      0.200000      0.166667   \n",
       "        454      0.222222      0.166667      0.133333      0.111111   \n",
       "        449      0.222222      0.250000      0.200000      0.166667   \n",
       "        448      0.111111      0.083333      0.066667      0.111111   \n",
       "        450      0.222222      0.166667      0.200000      0.166667   \n",
       "        446      0.111111      0.083333      0.066667      0.055556   \n",
       "\n",
       "             pred_knn_7_1  pred_knn_8_1  pred_knn_9_1  pred_knn_10_1  \\\n",
       "race_id                                                                \n",
       "52996   455      0.095238      0.083333      0.074074       0.066667   \n",
       "        452      0.142857      0.125000      0.111111       0.100000   \n",
       "        451      0.142857      0.166667      0.148148       0.166667   \n",
       "        453      0.095238      0.083333      0.074074       0.066667   \n",
       "        456      0.095238      0.125000      0.111111       0.100000   \n",
       "        447      0.142857      0.125000      0.111111       0.133333   \n",
       "        454      0.095238      0.125000      0.148148       0.133333   \n",
       "        449      0.142857      0.166667      0.148148       0.166667   \n",
       "        448      0.095238      0.083333      0.074074       0.066667   \n",
       "        450      0.142857      0.125000      0.111111       0.133333   \n",
       "        446      0.095238      0.083333      0.074074       0.066667   \n",
       "\n",
       "             pred_stacked_mlp_relu_1  \n",
       "race_id                               \n",
       "52996   455                 2.634349  \n",
       "        452                 2.658501  \n",
       "        451                 0.320236  \n",
       "        453                 2.624956  \n",
       "        456                 2.638677  \n",
       "        447                 0.274401  \n",
       "        454                 2.660601  \n",
       "        449                 2.630397  \n",
       "        448                 2.575784  \n",
       "        450                 2.616048  \n",
       "        446                 2.594701  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploration.random_race(df, cols=['position', 'declared_player_count', 'sub_category', 'num', 'final_odds', 'final_odds_ref', 'pred_stacked'] + ['pred_stacked_{}'.format(pos+1) for pos in range(1,8)] + ['pred_xgb_100_1', 'pred_rf_100_1', 'pred_knn_5_1', 'pred_mlp_100_1', 'pred_ridge_1_1']).sort_values(by='pred_stacked_8', ascending=False)\n",
    "exploration.random_race(df, cols=['position', 'declared_player_count', 'sub_category', 'num', 'final_odds', 'final_odds_unibet', 'target_pos', 'pred_xgb_100_1'] + ['pred_{}_1'.format(model['name']) for model in program.model.models] + ['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models]).sort_values(by='position', ascending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbets = bet(df, program.model.features, program.model.categorical_features, \\n    N=3, max_odds=30, break_on_bet=False, break_on_odds=False, \\n    targets=['pred_rnd', 'final_odds_ref', 'pred_sum'] + ['pred_{}_1'.format(model['name']) for model in program.model.models] + ['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models]\\n   )\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = program.df\n",
    "df['pred_rnd'] = np.random.rand(df.shape[0])\n",
    "df['pred_sum'] = df[['pred_{}_1'.format(model['name']) for model in program.model.models ]].sum(axis=1)\n",
    "\n",
    "#for model in program.model.models:\n",
    "#    df['pred_{}_1_3'.format(model['name'])] = df[ ['pred_{}_{}'.format(model['name'], i) for i in range(1,4) ] ].sum(axis=1)\n",
    "#    df['pred_{}_2_4'.format(model['name'])] = df[ ['pred_{}_{}'.format(model['name'], i) for i in range(2,5) ] ].sum(axis=1)\n",
    "\n",
    "\n",
    "for model in program.model.models:\n",
    "    df['pred_minus_ref_{}'.format(model['name'])] = df['pred_{}_1'.format(model['name'])] - df['final_odds_ref']\n",
    "    \n",
    "for model in program.model.stacked_models:\n",
    "    df['pred_minus_ref_stacked_{}'.format(model['name'])] = df['pred_stacked_{}_1'.format(model['name'])] - df['final_odds_ref']\n",
    "\n",
    "\n",
    "\n",
    "bets = bet(df, program.model.features, program.model.categorical_features, \n",
    "    N=3, max_odds=30, break_on_bet=False, break_on_odds=False, \n",
    "    targets=['pred_rnd', 'final_odds_ref', 'pred_sum'] + ['pred_{}_{}'.format(model['name'], i+1) for i in range(program.model.params['n_targets']) for model in program.model.models] + ['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models] \n",
    "   )\n",
    "\n",
    "'''\n",
    "bets = bet(df, program.model.features, program.model.categorical_features, \n",
    "    N=3, max_odds=30, break_on_bet=False, break_on_odds=False, \n",
    "    targets=['pred_rnd', 'final_odds_ref', 'pred_sum'] + ['pred_{}_1'.format(model['name']) for model in program.model.models] + ['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models]\n",
    "   )\n",
    "'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program.df.race_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_bb(bb, f):\n",
    "    results = []\n",
    "\n",
    "    for s in bb[f].value_counts().index:\n",
    "        results = []\n",
    "        x = bb[ (bb[f] == s) & (bb['pred_std'] != 0) & (bb['pred'] != 0) ].copy()\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "        #print(\"---\\n{}\\t{:+.2f}\\t{:+.2f}\\t{:+.2f}\\n---\".format(s, x['profit'].sum(), x['bet'].sum(), len(x)))\n",
    "\n",
    "        fig, axs = plt.subplots(1,1)\n",
    "\n",
    "        for t in x['target'].value_counts().index:\n",
    "            bbb = x[(x['target'] == t)].copy()\n",
    "            #bbb = bbb[ (bbb['pred']>bbb['pred'].quantile(0.85)) ].copy()\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                'idx_1': s,\n",
    "                'idx_2': t,\n",
    "                'profit': bbb.profit.sum(),\n",
    "                'profit_place': bbb.profit_placed.sum(),\n",
    "                'bet': bbb.bet.sum(),\n",
    "                'bets': bbb.bet.count(),\n",
    "                'avg': bbb.profit.sum() / bbb.bet.sum()\n",
    "            })\n",
    "\n",
    "            '''\n",
    "            bbb['stash'] = bbb['profit'].cumsum()\n",
    "            bbb['cbet'] = bbb['bet'].cumsum()\n",
    "\n",
    "            fig, axs = plt.subplots(1,1)\n",
    "            bbb['stash'].plot(figsize=(6, 2))\n",
    "            bbb['cbet'].plot(figsize=(6, 2))\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #print(\"{:10s}: \\t {:+.2f} \\t {:+.0f} \\t {:+.2f}\".format(t, bbb.profit.sum(), bbb.profit.count(), bbb.profit.mean()) )\n",
    "\n",
    "            bbb['stash'] = bbb['profit'].cumsum()\n",
    "            bbb['cbet'] = bbb['bet'].cumsum()\n",
    "\n",
    "            bbb['stash'].plot(figsize=(10, 2))\n",
    "            bbb['cbet'].plot(figsize=(10, 2))\n",
    "\n",
    "        results = pd.DataFrame(results)\n",
    "        results = results.set_index(['idx_1', 'idx_2'])\n",
    "        print(results.sort_values(by='avg', ascending=False))\n",
    "\n",
    "\n",
    "        plt.show()    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries = list(bets['country'].value_counts()[0:10].index)\n",
    "#sub_categories = list(bets['sub_category'].value_counts()[0:10].index)\n",
    "\n",
    "#%store countries\n",
    "#%store sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r params\n",
    "%store -r countries\n",
    "%store -r sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "target = 'final_odds_ref'\n",
    "\n",
    "c_min = bets[(bets['target'] == target)]['pred'].min()\n",
    "c_mean = bets[(bets['target'] == target)]['pred'].mean()\n",
    "c_max = bets[(bets['target'] == target)]['pred'].max()\n",
    "\n",
    "space = [\n",
    "          Real(1, 10, name='min_odds'),\n",
    "          Real(10, 30, name='max_odds'),\n",
    "          Real(c_min, c_mean, name='min_pred'),\n",
    "          Real(c_mean, c_max, name='max_pred'),\n",
    "          Integer(5, 25, name='max_players')] + [\n",
    "          Integer(0,1, name='country_{}'.format(country)) for country in countries] + [\n",
    "          Integer(0,1, name='sub_category_{}'.format(sub_category)) for sub_category in sub_categories] + [\n",
    "          Integer(0,1, name='nb_{}'.format(n)) for n in range(0,3)]\n",
    "         \n",
    "def x_to_params(x):\n",
    "    params = {}\n",
    "    \n",
    "    params['min_odds'] = x[0]\n",
    "    params['max_odds'] = x[1]\n",
    "    params['max_pred'] = x[3]\n",
    "    params['min_pred'] = x[2]\n",
    "    params['max_players'] = x[4]\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        params['country_{}'.format(country)] = x[5+i]\n",
    "        \n",
    "    for i, sc in enumerate(sub_categories):\n",
    "        params['sub_category_{}'.format(sc)] = x[5+len(countries)+i]\n",
    "        \n",
    "    for n in range(0,3):\n",
    "        params['nb_{}'.format(n)] = x[5+len(countries)+len(sub_categories)+n]\n",
    "\n",
    "    return params\n",
    "\n",
    "@use_named_args(space)\n",
    "def f(**params):\n",
    "    return ff(params)\n",
    "    \n",
    "def ff(params, train=True):\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    b = bets[ (bets['target']==target) & (bets['pred_std'] >= 0)]\n",
    "    \n",
    "    b = b[ (b['odds_ref'] > params['min_odds']) & (b['odds_ref'] < params['max_odds']) & (b['declared_player_count'] > 1) & (b['declared_player_count'] <= params['max_players']) ]\n",
    "    \n",
    "    b = b[(b['pred'] > params['min_pred']) & (b['pred'] < params['max_pred'])]\n",
    "    \n",
    "    for country in countries:\n",
    "        if params['country_{}'.format(country)] == 0:\n",
    "            b = b[ b['country'] != country ]\n",
    "            \n",
    "    for sub_category in sub_categories:\n",
    "        if params['sub_category_{}'.format(sub_category)] == 0:\n",
    "            b = b[ b['sub_category'] != sub_category ]\n",
    "            \n",
    "    for n in range(0,3):\n",
    "        if params['nb_{}'.format(n)] == 0:\n",
    "            b = b[ b['nb'] != n]\n",
    "    \n",
    "    p = b.profit.sum()\n",
    "    bet = b.bet.sum()\n",
    "    \n",
    "    print(\"{:+.2f} {:+.2f}\\n\".format(p, bet))\n",
    "        \n",
    "    if bet == 0:\n",
    "        return 0\n",
    "    \n",
    "    if not train:\n",
    "        return b\n",
    "    \n",
    "    return - (p)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skopt import dummy_minimize, gp_minimize, gbrt_minimize\n",
    "\n",
    "#res = gbrt_minimize(f, space, n_calls=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(res.x, res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = x_to_params(res.x)\n",
    "#%store params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(program.model.models[0]['estimators'])\n",
    "program.model.hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = ff(params, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    avg  bet  bets  profit  profit_place\n",
      "idx_1  idx_2                                                            \n",
      "ATTELE pred_stacked_mlp_relu_1 -0.94025   12    12 -11.283          -7.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bb = bets\n",
    "bb = bets[ (bets['sub_category']=='AUTOSTART') & (bets['nb']==2) & (bets['target']=='pred_stacked_mlp_relu_1') & (bets['odds_ref']<8) & (bets['odds_ref']>3) & (bets['pred']<=1) ].copy()\n",
    "#bb = bets[ (bets['country']=='FRA') & (bets['sub_category']!='COURSE_A_CONDITIONS') & (bets['nb']==0) & (bets['odds_ref']>=bets['odds_1']) & (bets['odds_ref']<20) & (bets['target']!='psred_mlp_20_1') ].copy()\n",
    "#bb = bets[ (bets['country']=='FRA') & (bets['sub_category']=='AUTOSTART') & (bets['nb']<=0) & (bets['odds_ref']>=0) & (bets['odds_ref']<20) ].copy()\n",
    "#bb = bets[ (bets['country']=='FRA') & (bets['sub_category']!='COURSE_A_CONDITIONS') & (bets['nb']==0) & ( (bets['target']=='pred_knn_10_1') | (bets['target']=='pred_minus_ref_lasso_1') ) & (bets['odds_ref']>10) & (bets['odds_ref']<20) & (bets['pred']>20)].copy()        \n",
    "#bb = bets[ (bets['country']=='FRA') & (bets['nb']==0) & (bets['odds_ref']>10) & (bets['odds_ref']<20) & (bets['pred']>0)].copy()\n",
    "#bb = bb.groupby('id').filter(lambda r: r['num'].count() == 2)\n",
    "#graph_bb( bets[(bets['target']=='pred_lasso_0.1_1') & (bets['nb']==0) & (bets['odds_ref']>5) & (bets['odds_ref']<20) & (bets['pred']>0.)], 'sub_category')\n",
    "#bb['profit'] = bb['profit'] * 1/(1+bb['nb'])\n",
    "#bb['bet'] = bb['bet'] * 1/(1+bb['nb'])\n",
    "\n",
    "#bb['profit'] = bb['profit'] * np.round(bb['pred']*100)\n",
    "#bb['bet'] = bb['bet'] * np.round(bb['pred']*100)\n",
    "\n",
    "graph_bb(bb, 'category')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[ (df['position']==1)  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['placed_3_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
