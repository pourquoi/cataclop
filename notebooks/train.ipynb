{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cataclop.ml import preprocessing\n",
    "from cataclop.ml import exploration\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from cataclop.ml.pipeline import factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = factories.Program.factory('default', version='1.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1322 races\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing model data\n",
      "training nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 0.1037\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1004\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1021\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0996\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0988\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1008\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0986\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0990\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0990\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1002\n",
      "33/33 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27421652612896147\n",
      "training nn_51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 2s 10ms/step - loss: 0.1692\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.1486\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1389\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1273\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1262\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1158\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1112\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1111\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1050\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1038\n",
      "33/33 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27847051507387277\n",
      "training nn_101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 0.1332\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1280\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1155\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1084\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1065\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1108\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1044\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1058\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1034\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1006\n",
      "33/33 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27772554018488005\n",
      "training nn_151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1441\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1296\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1218\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1174\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1089\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1051\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1079\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1036\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1041\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1040\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.2734523669715692\n",
      "training xgb_10\n",
      "mea: 0.2654628205242537\n",
      "training xgb_30\n",
      "mea: 0.26285637490678143\n",
      "training xgb_50\n",
      "mea: 0.26153385826118025\n",
      "training xgb_100\n",
      "mea: 0.26127728493119035\n",
      "training knn_5\n",
      "mea: 0.28277281443729185\n",
      "training nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1056\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1020\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.100 - 0s 3ms/step - loss: 0.1010\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1008\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0988\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1018\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0986\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0989\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0980\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0981\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27149069191477826\n",
      "training nn_51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1150\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1093\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1057\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1091\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1031\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1063\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1043\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1036\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1030\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.2764194621363016\n",
      "training nn_101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1189\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1096\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1055\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1062\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1096\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1017\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1063\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1053\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1077\n",
      "33/33 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.2786589513091079\n",
      "training nn_151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1101\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1066\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0997\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1025\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1000\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0999\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0976\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0972\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0948\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0960\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.2724909030212137\n",
      "training xgb_10\n",
      "mea: 0.2641027318535442\n",
      "training xgb_30\n",
      "mea: 0.2632685340780424\n",
      "training xgb_50\n",
      "mea: 0.2619723966147117\n",
      "training xgb_100\n",
      "mea: 0.26128679113824754\n",
      "training knn_5\n",
      "mea: 0.2822113991699358\n",
      "training nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1492\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1227\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1213\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1167\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1146\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1098\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1082\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1011\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0986\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27623344561629465\n",
      "training nn_51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 6ms/step - loss: 0.1206\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1031\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1069\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.1049\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0994\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1043A: 0s - loss: 0.\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0990\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1026\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1020\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1016\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27719804585488517\n",
      "training nn_101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 3ms/step - loss: 0.1405\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1222\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1061\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1048\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1045\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1031\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1037\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0982\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0995\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1005\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.2735618698623141\n",
      "training nn_151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 1s 4ms/step - loss: 0.1061\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1036\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1025\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.1037\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1009\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.1008\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0965\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0996\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.0953\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.27385754471048834\n",
      "training xgb_10\n",
      "mea: 0.26512867499971876\n",
      "training xgb_30\n",
      "mea: 0.2616530921053748\n",
      "training xgb_50\n",
      "mea: 0.26100050516137546\n",
      "training xgb_100\n",
      "mea: 0.2617017789583596\n",
      "training knn_5\n",
      "mea: 0.2845590790048466\n",
      "training stacked_nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 5ms/step - loss: 0.1551\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1427\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1326\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1218\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1047\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0949\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0933\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0882\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0813\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.4195730241902824\n",
      "training stacked_nn_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 5ms/step - loss: 0.0560\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0484\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0450\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0404\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0359\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0345\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0331\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.029 - 0s 4ms/step - loss: 0.0294\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0277\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0254\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.25738693041523686\n",
      "training stacked_nn_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.1083\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0963\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0903\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0806\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0758\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0689\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0641\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0599\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0561\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0527\n",
      "33/33 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.36279992698928687\n",
      "training stacked_nn_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 5ms/step - loss: 0.0448\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0398\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0322\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0329\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0319\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0299\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0289\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0295\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0240\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0233\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.24464402704586105\n",
      "training stacked_nn_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.1343\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1220\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - -0s -1184us/step - loss: 0.1095\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1080\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0970\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0945\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0880\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0834\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0812\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0690\n",
      "33/33 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.3883884658848198\n",
      "training stacked_nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4081\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3909\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3546\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3645\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3528\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3312\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3252\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3143\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2961\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2953\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.681636589896272\n",
      "training stacked_nn_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 0.1705\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1662\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1507\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1538\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1428\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1324\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1229\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1199\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1163\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1097\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.4394149135008091\n",
      "training stacked_nn_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 0.3610\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3400\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3356\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3278\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3155\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2901\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3024\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2759\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2566\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2603\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.6109757675677975\n",
      "training stacked_nn_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 5ms/step - loss: 0.2186\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1963\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1951\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1849\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1757\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1731\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1693\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1604\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1421\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1396\n",
      "33/33 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.5446908780616667\n",
      "training stacked_nn_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 5ms/step - loss: 0.2106\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1918\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1874\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1783\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1748\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1588\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1605\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1416\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1372\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1258\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.5161507903789893\n",
      "training stacked_nn_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.4139\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3980\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3832\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3691\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3639\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3524\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3474\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3310\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3210\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3012\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.711190279496821\n",
      "training stacked_nn_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 5ms/step - loss: 0.2480\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2289\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2238\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2130\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2012\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1871\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1761\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1666\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1636\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1508\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.5495057232203134\n",
      "training stacked_nn_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.1265\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.1170\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1084\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1015\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0919\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0856\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0816\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0785\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0742\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0728\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.34144185419943274\n",
      "training stacked_nn_7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.1302\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1220\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1171\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1049\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1024\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0875\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0830\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0756\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0711\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0670\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.37565715157857754\n",
      "training stacked_nn_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.2664\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2492\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2398\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2271\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2209\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2025\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1960\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1871\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1751\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1656\n",
      "33/33 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mea: 0.49287909326576607\n"
     ]
    }
   ],
   "source": [
    "program.train(dataset_params = {\n",
    "    'from': '2021-01-01',\n",
    "    'to': '2021-02-01',\n",
    "    #'hippodrome': ['DEAUVILLE']\n",
    "    #'countries': ['FRA'],\n",
    "    #'categories': ['PLAT'],\n",
    "    #'sub_categories': ['HANDICAP'],\n",
    "    #'prize_min': 40000\n",
    "}, model_params = {\n",
    "    'seed': 123456,\n",
    "    'kfolds': 3,\n",
    "    'nan_flag': 0,\n",
    "    'n_targets': 1,\n",
    "}, dataset_reload=True, model='default', dataset='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>race_id</th>\n",
       "      <th>age</th>\n",
       "      <th>num</th>\n",
       "      <th>race_count</th>\n",
       "      <th>victory_count</th>\n",
       "      <th>placed_count</th>\n",
       "      <th>placed_2_count</th>\n",
       "      <th>placed_3_count</th>\n",
       "      <th>earnings</th>\n",
       "      <th>victory_earnings</th>\n",
       "      <th>placed_earnings</th>\n",
       "      <th>year_earnings</th>\n",
       "      <th>prev_year_earnings</th>\n",
       "      <th>post_position</th>\n",
       "      <th>position</th>\n",
       "      <th>handicap_weight</th>\n",
       "      <th>handicap_distance</th>\n",
       "      <th>trueskill_mu</th>\n",
       "      <th>trueskill_sigma</th>\n",
       "      <th>time</th>\n",
       "      <th>hist_1_days</th>\n",
       "      <th>hist_2_days</th>\n",
       "      <th>hist_3_days</th>\n",
       "      <th>winner_dividend</th>\n",
       "      <th>placed_dividend</th>\n",
       "      <th>final_odds</th>\n",
       "      <th>final_odds_offline</th>\n",
       "      <th>final_odds_unibet</th>\n",
       "      <th>final_odds_ref</th>\n",
       "      <th>final_odds_ref_offline</th>\n",
       "      <th>final_odds_ref_unibet</th>\n",
       "      <th>trainer_winning_rate</th>\n",
       "      <th>trainer_avg_winning_dividend</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>herder_id</th>\n",
       "      <th>owner_id</th>\n",
       "      <th>num_race</th>\n",
       "      <th>num_bis</th>\n",
       "      <th>prize</th>\n",
       "      <th>distance</th>\n",
       "      <th>declared_player_count</th>\n",
       "      <th>session_id</th>\n",
       "      <th>num_session</th>\n",
       "      <th>hippodrome_id</th>\n",
       "      <th>hist_1_pos</th>\n",
       "      <th>hist_2_pos</th>\n",
       "      <th>hist_3_pos</th>\n",
       "      <th>hist_4_pos</th>\n",
       "      <th>hist_5_pos</th>\n",
       "      <th>hist_6_pos</th>\n",
       "      <th>speed</th>\n",
       "      <th>win</th>\n",
       "      <th>final_odds_ref_inv</th>\n",
       "      <th>race_count_mean</th>\n",
       "      <th>race_count_std</th>\n",
       "      <th>race_count_amin</th>\n",
       "      <th>race_count_amax</th>\n",
       "      <th>hist_1_pos_mean</th>\n",
       "      <th>hist_1_pos_std</th>\n",
       "      <th>hist_1_pos_amin</th>\n",
       "      <th>hist_1_pos_amax</th>\n",
       "      <th>hist_2_pos_mean</th>\n",
       "      <th>hist_2_pos_std</th>\n",
       "      <th>hist_2_pos_amin</th>\n",
       "      <th>hist_2_pos_amax</th>\n",
       "      <th>hist_3_pos_mean</th>\n",
       "      <th>hist_3_pos_std</th>\n",
       "      <th>hist_3_pos_amin</th>\n",
       "      <th>hist_3_pos_amax</th>\n",
       "      <th>post_position_mean</th>\n",
       "      <th>post_position_std</th>\n",
       "      <th>post_position_amin</th>\n",
       "      <th>post_position_amax</th>\n",
       "      <th>victory_count_mean</th>\n",
       "      <th>victory_count_std</th>\n",
       "      <th>victory_count_amin</th>\n",
       "      <th>victory_count_amax</th>\n",
       "      <th>placed_2_count_mean</th>\n",
       "      <th>placed_2_count_std</th>\n",
       "      <th>placed_2_count_amin</th>\n",
       "      <th>placed_2_count_amax</th>\n",
       "      <th>placed_3_count_mean</th>\n",
       "      <th>placed_3_count_std</th>\n",
       "      <th>placed_3_count_amin</th>\n",
       "      <th>placed_3_count_amax</th>\n",
       "      <th>victory_earnings_mean</th>\n",
       "      <th>victory_earnings_std</th>\n",
       "      <th>victory_earnings_amin</th>\n",
       "      <th>victory_earnings_amax</th>\n",
       "      <th>placed_earnings_mean</th>\n",
       "      <th>placed_earnings_std</th>\n",
       "      <th>placed_earnings_amin</th>\n",
       "      <th>placed_earnings_amax</th>\n",
       "      <th>prev_year_earnings_mean</th>\n",
       "      <th>prev_year_earnings_std</th>\n",
       "      <th>prev_year_earnings_amin</th>\n",
       "      <th>prev_year_earnings_amax</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_2_days_amax</th>\n",
       "      <th>hist_3_days_mean</th>\n",
       "      <th>hist_3_days_std</th>\n",
       "      <th>hist_3_days_amin</th>\n",
       "      <th>hist_3_days_amax</th>\n",
       "      <th>trainer_winning_rate_mean</th>\n",
       "      <th>trainer_winning_rate_std</th>\n",
       "      <th>trainer_winning_rate_amin</th>\n",
       "      <th>trainer_winning_rate_amax</th>\n",
       "      <th>trainer_avg_winning_dividend_mean</th>\n",
       "      <th>trainer_avg_winning_dividend_std</th>\n",
       "      <th>trainer_avg_winning_dividend_amin</th>\n",
       "      <th>trainer_avg_winning_dividend_amax</th>\n",
       "      <th>race_count_r</th>\n",
       "      <th>hist_1_pos_r</th>\n",
       "      <th>hist_2_pos_r</th>\n",
       "      <th>hist_3_pos_r</th>\n",
       "      <th>post_position_r</th>\n",
       "      <th>victory_count_r</th>\n",
       "      <th>placed_2_count_r</th>\n",
       "      <th>placed_3_count_r</th>\n",
       "      <th>victory_earnings_r</th>\n",
       "      <th>placed_earnings_r</th>\n",
       "      <th>prev_year_earnings_r</th>\n",
       "      <th>handicap_distance_r</th>\n",
       "      <th>handicap_weight_r</th>\n",
       "      <th>final_odds_ref_r</th>\n",
       "      <th>final_odds_ref_offline_r</th>\n",
       "      <th>trueskill_mu_r</th>\n",
       "      <th>trueskill_sigma_r</th>\n",
       "      <th>hist_1_days_r</th>\n",
       "      <th>hist_2_days_r</th>\n",
       "      <th>hist_3_days_r</th>\n",
       "      <th>trainer_winning_rate_r</th>\n",
       "      <th>trainer_avg_winning_dividend_r</th>\n",
       "      <th>race_winner_dividend</th>\n",
       "      <th>odds_0</th>\n",
       "      <th>odds_1</th>\n",
       "      <th>odds_2</th>\n",
       "      <th>odds_3</th>\n",
       "      <th>odds_4</th>\n",
       "      <th>odds_5</th>\n",
       "      <th>odds_6</th>\n",
       "      <th>odds_7</th>\n",
       "      <th>odds_8</th>\n",
       "      <th>odds_9</th>\n",
       "      <th>odds_10</th>\n",
       "      <th>odds_11</th>\n",
       "      <th>odds_12</th>\n",
       "      <th>odds_13</th>\n",
       "      <th>odds_14</th>\n",
       "      <th>odds_15</th>\n",
       "      <th>odds_16</th>\n",
       "      <th>odds_17</th>\n",
       "      <th>odds_18</th>\n",
       "      <th>odds_19</th>\n",
       "      <th>target_returns</th>\n",
       "      <th>target</th>\n",
       "      <th>target_stacked</th>\n",
       "      <th>pred_nn_1_1</th>\n",
       "      <th>pred_nn_51_1</th>\n",
       "      <th>pred_nn_101_1</th>\n",
       "      <th>pred_nn_151_1</th>\n",
       "      <th>pred_xgb_10_1</th>\n",
       "      <th>pred_xgb_30_1</th>\n",
       "      <th>pred_xgb_50_1</th>\n",
       "      <th>pred_xgb_100_1</th>\n",
       "      <th>pred_knn_5_1</th>\n",
       "      <th>pred_nn_1_std</th>\n",
       "      <th>pred_nn_1_min</th>\n",
       "      <th>pred_nn_1_max</th>\n",
       "      <th>pred_nn_51_std</th>\n",
       "      <th>pred_nn_51_min</th>\n",
       "      <th>pred_nn_51_max</th>\n",
       "      <th>pred_nn_101_std</th>\n",
       "      <th>pred_nn_101_min</th>\n",
       "      <th>pred_nn_101_max</th>\n",
       "      <th>pred_nn_151_std</th>\n",
       "      <th>pred_nn_151_min</th>\n",
       "      <th>pred_nn_151_max</th>\n",
       "      <th>pred_xgb_10_std</th>\n",
       "      <th>pred_xgb_10_min</th>\n",
       "      <th>pred_xgb_10_max</th>\n",
       "      <th>pred_xgb_30_std</th>\n",
       "      <th>pred_xgb_30_min</th>\n",
       "      <th>pred_xgb_30_max</th>\n",
       "      <th>pred_xgb_50_std</th>\n",
       "      <th>pred_xgb_50_min</th>\n",
       "      <th>pred_xgb_50_max</th>\n",
       "      <th>pred_xgb_100_std</th>\n",
       "      <th>pred_xgb_100_min</th>\n",
       "      <th>pred_xgb_100_max</th>\n",
       "      <th>pred_knn_5_std</th>\n",
       "      <th>pred_knn_5_min</th>\n",
       "      <th>pred_knn_5_max</th>\n",
       "      <th>pred_stacked_stacked_nn_1_1</th>\n",
       "      <th>pred_stacked_stacked_nn_3_1</th>\n",
       "      <th>pred_stacked_stacked_nn_5_1</th>\n",
       "      <th>pred_stacked_stacked_nn_7_1</th>\n",
       "      <th>pred_stacked_stacked_nn_9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>2468.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>1479.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3006.00000</td>\n",
       "      <td>2788.000000</td>\n",
       "      <td>2818.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3.080000e+03</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "      <td>3080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12058.309740</td>\n",
       "      <td>995.287662</td>\n",
       "      <td>5.892208</td>\n",
       "      <td>7.043506</td>\n",
       "      <td>31.653247</td>\n",
       "      <td>3.504221</td>\n",
       "      <td>14.121104</td>\n",
       "      <td>3.234416</td>\n",
       "      <td>2.990260</td>\n",
       "      <td>8.205089e+06</td>\n",
       "      <td>14.697742</td>\n",
       "      <td>13.154541</td>\n",
       "      <td>4.894091</td>\n",
       "      <td>11.973591</td>\n",
       "      <td>7.043506</td>\n",
       "      <td>5.974068</td>\n",
       "      <td>7.366883</td>\n",
       "      <td>1646.099026</td>\n",
       "      <td>25.632188</td>\n",
       "      <td>4.491025</td>\n",
       "      <td>194437.728195</td>\n",
       "      <td>32119.038961</td>\n",
       "      <td>85587.057468</td>\n",
       "      <td>98279.605844</td>\n",
       "      <td>71.347403</td>\n",
       "      <td>70.373377</td>\n",
       "      <td>37.40316</td>\n",
       "      <td>35.473350</td>\n",
       "      <td>35.558588</td>\n",
       "      <td>3044.738344</td>\n",
       "      <td>10572.729610</td>\n",
       "      <td>31.064152</td>\n",
       "      <td>7565.010366</td>\n",
       "      <td>7564.709614</td>\n",
       "      <td>5352.513312</td>\n",
       "      <td>659.813961</td>\n",
       "      <td>561.243506</td>\n",
       "      <td>1143.316431</td>\n",
       "      <td>2434.752922</td>\n",
       "      <td>4.701948</td>\n",
       "      <td>2.003205</td>\n",
       "      <td>9.800963</td>\n",
       "      <td>2354.245130</td>\n",
       "      <td>13.087013</td>\n",
       "      <td>144.403571</td>\n",
       "      <td>3.099351</td>\n",
       "      <td>9.421429</td>\n",
       "      <td>6.238961</td>\n",
       "      <td>6.112013</td>\n",
       "      <td>5.913961</td>\n",
       "      <td>5.475325</td>\n",
       "      <td>5.113961</td>\n",
       "      <td>4.805195</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.080195</td>\n",
       "      <td>0.096572</td>\n",
       "      <td>31.653247</td>\n",
       "      <td>14.165818</td>\n",
       "      <td>11.997727</td>\n",
       "      <td>60.481818</td>\n",
       "      <td>6.238961</td>\n",
       "      <td>3.148605</td>\n",
       "      <td>1.435714</td>\n",
       "      <td>9.937987</td>\n",
       "      <td>6.112013</td>\n",
       "      <td>3.216126</td>\n",
       "      <td>1.286364</td>\n",
       "      <td>9.934091</td>\n",
       "      <td>5.913961</td>\n",
       "      <td>3.278834</td>\n",
       "      <td>1.159416</td>\n",
       "      <td>9.865584</td>\n",
       "      <td>7.043506</td>\n",
       "      <td>3.919455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.087013</td>\n",
       "      <td>3.504221</td>\n",
       "      <td>2.126733</td>\n",
       "      <td>0.711688</td>\n",
       "      <td>7.838961</td>\n",
       "      <td>3.234416</td>\n",
       "      <td>2.086545</td>\n",
       "      <td>0.557468</td>\n",
       "      <td>7.471104</td>\n",
       "      <td>2.990260</td>\n",
       "      <td>2.147648</td>\n",
       "      <td>0.427922</td>\n",
       "      <td>7.599675</td>\n",
       "      <td>14.697742</td>\n",
       "      <td>1.074520</td>\n",
       "      <td>12.545733</td>\n",
       "      <td>15.798547</td>\n",
       "      <td>13.154541</td>\n",
       "      <td>1.779444</td>\n",
       "      <td>9.234344</td>\n",
       "      <td>14.797916</td>\n",
       "      <td>11.973591</td>\n",
       "      <td>2.781866</td>\n",
       "      <td>5.813754</td>\n",
       "      <td>14.310481</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>98279.605844</td>\n",
       "      <td>5442.977618</td>\n",
       "      <td>81530.091883</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>7565.010366</td>\n",
       "      <td>17906.921593</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>52370.273637</td>\n",
       "      <td>7564.709614</td>\n",
       "      <td>17907.568017</td>\n",
       "      <td>-0.997956</td>\n",
       "      <td>52371.675985</td>\n",
       "      <td>3311.688312</td>\n",
       "      <td>1.730218e-18</td>\n",
       "      <td>-1.297663e-18</td>\n",
       "      <td>-8.506904e-18</td>\n",
       "      <td>-8.651089e-19</td>\n",
       "      <td>7142.857143</td>\n",
       "      <td>4350.649351</td>\n",
       "      <td>3993.506494</td>\n",
       "      <td>2.511699e-16</td>\n",
       "      <td>3993.506494</td>\n",
       "      <td>4448.051948</td>\n",
       "      <td>87305.194805</td>\n",
       "      <td>71136.363636</td>\n",
       "      <td>8.939458e-18</td>\n",
       "      <td>8181.818182</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-1.777799e-16</td>\n",
       "      <td>1071.428571</td>\n",
       "      <td>25032.467532</td>\n",
       "      <td>81525.974026</td>\n",
       "      <td>1.023712e-17</td>\n",
       "      <td>-7.641795e-18</td>\n",
       "      <td>926.224026</td>\n",
       "      <td>3.363117</td>\n",
       "      <td>5.485487</td>\n",
       "      <td>7.339188</td>\n",
       "      <td>9.524123</td>\n",
       "      <td>11.848052</td>\n",
       "      <td>371.631039</td>\n",
       "      <td>1641.440617</td>\n",
       "      <td>3560.546753</td>\n",
       "      <td>8077.492532</td>\n",
       "      <td>12920.700325</td>\n",
       "      <td>23472.412338</td>\n",
       "      <td>33864.409740</td>\n",
       "      <td>44613.282468</td>\n",
       "      <td>59805.026948</td>\n",
       "      <td>68991.280519</td>\n",
       "      <td>82325.050649</td>\n",
       "      <td>94260.474026</td>\n",
       "      <td>96505.358442</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.713474</td>\n",
       "      <td>0.563560</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.550192</td>\n",
       "      <td>0.552409</td>\n",
       "      <td>0.561827</td>\n",
       "      <td>0.561101</td>\n",
       "      <td>0.540216</td>\n",
       "      <td>0.560042</td>\n",
       "      <td>0.562125</td>\n",
       "      <td>0.562586</td>\n",
       "      <td>0.567399</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.489621</td>\n",
       "      <td>0.603030</td>\n",
       "      <td>0.047199</td>\n",
       "      <td>0.467093</td>\n",
       "      <td>0.614685</td>\n",
       "      <td>0.049794</td>\n",
       "      <td>0.484004</td>\n",
       "      <td>0.636122</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>0.502969</td>\n",
       "      <td>0.637749</td>\n",
       "      <td>0.051727</td>\n",
       "      <td>0.449214</td>\n",
       "      <td>0.619363</td>\n",
       "      <td>0.078528</td>\n",
       "      <td>0.421228</td>\n",
       "      <td>0.686230</td>\n",
       "      <td>0.089374</td>\n",
       "      <td>0.405409</td>\n",
       "      <td>0.708236</td>\n",
       "      <td>0.104170</td>\n",
       "      <td>0.379497</td>\n",
       "      <td>0.735112</td>\n",
       "      <td>0.110182</td>\n",
       "      <td>0.389714</td>\n",
       "      <td>0.747217</td>\n",
       "      <td>0.615138</td>\n",
       "      <td>0.424664</td>\n",
       "      <td>0.447344</td>\n",
       "      <td>0.396618</td>\n",
       "      <td>0.475507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2559.063269</td>\n",
       "      <td>216.376235</td>\n",
       "      <td>1.938165</td>\n",
       "      <td>4.064684</td>\n",
       "      <td>28.738711</td>\n",
       "      <td>3.835525</td>\n",
       "      <td>13.266399</td>\n",
       "      <td>3.327855</td>\n",
       "      <td>3.177938</td>\n",
       "      <td>1.303455e+07</td>\n",
       "      <td>2.838504</td>\n",
       "      <td>4.403119</td>\n",
       "      <td>6.074194</td>\n",
       "      <td>5.057159</td>\n",
       "      <td>4.064684</td>\n",
       "      <td>3.606413</td>\n",
       "      <td>13.698126</td>\n",
       "      <td>1261.282374</td>\n",
       "      <td>6.916171</td>\n",
       "      <td>2.533135</td>\n",
       "      <td>28408.918957</td>\n",
       "      <td>46691.693698</td>\n",
       "      <td>35124.033872</td>\n",
       "      <td>13003.694215</td>\n",
       "      <td>408.748718</td>\n",
       "      <td>181.711819</td>\n",
       "      <td>53.71988</td>\n",
       "      <td>44.129618</td>\n",
       "      <td>44.798292</td>\n",
       "      <td>17110.659985</td>\n",
       "      <td>30720.020377</td>\n",
       "      <td>38.953914</td>\n",
       "      <td>26447.896556</td>\n",
       "      <td>26447.982695</td>\n",
       "      <td>3434.899283</td>\n",
       "      <td>667.244766</td>\n",
       "      <td>558.509603</td>\n",
       "      <td>942.329141</td>\n",
       "      <td>2092.263536</td>\n",
       "      <td>2.433019</td>\n",
       "      <td>0.811883</td>\n",
       "      <td>0.994653</td>\n",
       "      <td>610.204077</td>\n",
       "      <td>2.642661</td>\n",
       "      <td>30.848125</td>\n",
       "      <td>2.034263</td>\n",
       "      <td>11.479637</td>\n",
       "      <td>3.241704</td>\n",
       "      <td>3.309928</td>\n",
       "      <td>3.396127</td>\n",
       "      <td>3.594686</td>\n",
       "      <td>3.654670</td>\n",
       "      <td>3.762308</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.271639</td>\n",
       "      <td>0.103615</td>\n",
       "      <td>22.684714</td>\n",
       "      <td>11.616015</td>\n",
       "      <td>12.849227</td>\n",
       "      <td>47.366417</td>\n",
       "      <td>1.089158</td>\n",
       "      <td>0.468166</td>\n",
       "      <td>0.793214</td>\n",
       "      <td>0.348129</td>\n",
       "      <td>1.111378</td>\n",
       "      <td>0.470053</td>\n",
       "      <td>0.809458</td>\n",
       "      <td>0.349277</td>\n",
       "      <td>1.186885</td>\n",
       "      <td>0.507270</td>\n",
       "      <td>0.719227</td>\n",
       "      <td>0.621774</td>\n",
       "      <td>1.321331</td>\n",
       "      <td>0.763490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.642661</td>\n",
       "      <td>2.919996</td>\n",
       "      <td>1.473349</td>\n",
       "      <td>1.337735</td>\n",
       "      <td>5.843030</td>\n",
       "      <td>2.339350</td>\n",
       "      <td>1.303400</td>\n",
       "      <td>0.983433</td>\n",
       "      <td>5.147119</td>\n",
       "      <td>2.073357</td>\n",
       "      <td>1.286259</td>\n",
       "      <td>0.807966</td>\n",
       "      <td>5.139288</td>\n",
       "      <td>2.155155</td>\n",
       "      <td>1.610606</td>\n",
       "      <td>4.901551</td>\n",
       "      <td>1.196490</td>\n",
       "      <td>3.584105</td>\n",
       "      <td>1.998147</td>\n",
       "      <td>6.235615</td>\n",
       "      <td>3.199101</td>\n",
       "      <td>3.709751</td>\n",
       "      <td>2.264807</td>\n",
       "      <td>6.243228</td>\n",
       "      <td>3.240508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4098.090774</td>\n",
       "      <td>11673.132329</td>\n",
       "      <td>38806.321049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10129.596614</td>\n",
       "      <td>18094.486031</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>49951.752210</td>\n",
       "      <td>10129.601796</td>\n",
       "      <td>18093.979356</td>\n",
       "      <td>0.021959</td>\n",
       "      <td>49950.281755</td>\n",
       "      <td>17897.082106</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>25758.119551</td>\n",
       "      <td>20402.743428</td>\n",
       "      <td>19583.847372</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>19583.847372</td>\n",
       "      <td>20619.361481</td>\n",
       "      <td>33296.882774</td>\n",
       "      <td>45320.205096</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>27413.202266</td>\n",
       "      <td>0.958534</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>10297.054141</td>\n",
       "      <td>43327.033294</td>\n",
       "      <td>38814.972864</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>9.592205e-01</td>\n",
       "      <td>1167.476575</td>\n",
       "      <td>1.202791</td>\n",
       "      <td>1.503116</td>\n",
       "      <td>2.194979</td>\n",
       "      <td>2.756745</td>\n",
       "      <td>3.543852</td>\n",
       "      <td>5965.565224</td>\n",
       "      <td>12637.071224</td>\n",
       "      <td>18475.118646</td>\n",
       "      <td>27206.435774</td>\n",
       "      <td>33501.976746</td>\n",
       "      <td>42353.106940</td>\n",
       "      <td>47297.431866</td>\n",
       "      <td>49681.500838</td>\n",
       "      <td>49004.232568</td>\n",
       "      <td>46227.754417</td>\n",
       "      <td>38125.846993</td>\n",
       "      <td>23247.890312</td>\n",
       "      <td>18335.312206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.087487</td>\n",
       "      <td>0.313742</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.074318</td>\n",
       "      <td>0.092798</td>\n",
       "      <td>0.083384</td>\n",
       "      <td>0.068871</td>\n",
       "      <td>0.051841</td>\n",
       "      <td>0.078874</td>\n",
       "      <td>0.090634</td>\n",
       "      <td>0.106629</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.072614</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>0.080194</td>\n",
       "      <td>0.081837</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.082895</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>0.054724</td>\n",
       "      <td>0.055285</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>0.051980</td>\n",
       "      <td>0.037567</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.047066</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>0.074537</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.039151</td>\n",
       "      <td>0.089916</td>\n",
       "      <td>0.088057</td>\n",
       "      <td>0.149019</td>\n",
       "      <td>0.135086</td>\n",
       "      <td>0.140235</td>\n",
       "      <td>0.143173</td>\n",
       "      <td>0.081960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4991.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.529207</td>\n",
       "      <td>1.038827</td>\n",
       "      <td>119900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.093405</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>1.509231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.589899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>1.615893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.107691</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.642207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>75004.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>-0.869298</td>\n",
       "      <td>0.267609</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.293750</td>\n",
       "      <td>-2.807533</td>\n",
       "      <td>-2.879000e+00</td>\n",
       "      <td>-2.948482e+00</td>\n",
       "      <td>-2.746313e+00</td>\n",
       "      <td>-1.592196e+00</td>\n",
       "      <td>-2.428288</td>\n",
       "      <td>-2.391971</td>\n",
       "      <td>-2.205344</td>\n",
       "      <td>-3.556379e+00</td>\n",
       "      <td>-3.945335</td>\n",
       "      <td>-3.907250</td>\n",
       "      <td>-1.417835</td>\n",
       "      <td>-3.277191</td>\n",
       "      <td>-2.009616e+00</td>\n",
       "      <td>-1.831291</td>\n",
       "      <td>-3.637018</td>\n",
       "      <td>-2.889538e+00</td>\n",
       "      <td>-2.253203</td>\n",
       "      <td>-4.006938</td>\n",
       "      <td>-4.006938</td>\n",
       "      <td>-1.778568e+00</td>\n",
       "      <td>-1.630330e+00</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352517</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.330463</td>\n",
       "      <td>0.381320</td>\n",
       "      <td>0.368837</td>\n",
       "      <td>0.243548</td>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.145182</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352517</td>\n",
       "      <td>0.369244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330463</td>\n",
       "      <td>0.394664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381320</td>\n",
       "      <td>0.463837</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.368837</td>\n",
       "      <td>0.560051</td>\n",
       "      <td>0.031180</td>\n",
       "      <td>0.243548</td>\n",
       "      <td>0.619210</td>\n",
       "      <td>0.036341</td>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.626898</td>\n",
       "      <td>0.051582</td>\n",
       "      <td>0.145182</td>\n",
       "      <td>0.621927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134545</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.286546</td>\n",
       "      <td>0.148284</td>\n",
       "      <td>0.229626</td>\n",
       "      <td>0.100132</td>\n",
       "      <td>0.281769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10281.750000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.391350e+06</td>\n",
       "      <td>14.145786</td>\n",
       "      <td>13.231892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.435196</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.036082</td>\n",
       "      <td>2.393291</td>\n",
       "      <td>166625.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.70000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>8.675000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2448.750000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>346.500000</td>\n",
       "      <td>634.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.546884</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.434876</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.444444</td>\n",
       "      <td>2.875627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>2.906367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>3.002887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.029857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>1.103713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.182132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.028098</td>\n",
       "      <td>0.209101</td>\n",
       "      <td>11.867104</td>\n",
       "      <td>15.102012</td>\n",
       "      <td>12.828576</td>\n",
       "      <td>0.444466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.562389</td>\n",
       "      <td>11.206963</td>\n",
       "      <td>0.706875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.333710</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.078318</td>\n",
       "      <td>0.086327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.325295</td>\n",
       "      <td>0.801566</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-0.680766</td>\n",
       "      <td>-8.270520e-01</td>\n",
       "      <td>-8.437163e-01</td>\n",
       "      <td>-8.469199e-01</td>\n",
       "      <td>-8.366600e-01</td>\n",
       "      <td>-0.651570</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.682721</td>\n",
       "      <td>-5.917605e-01</td>\n",
       "      <td>-0.425542</td>\n",
       "      <td>-0.286117</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.044738</td>\n",
       "      <td>-5.765344e-01</td>\n",
       "      <td>-0.594489</td>\n",
       "      <td>-0.670365</td>\n",
       "      <td>-7.682838e-01</td>\n",
       "      <td>-0.718238</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-5.262352e-01</td>\n",
       "      <td>-5.032489e-01</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500941</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.488881</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.505955</td>\n",
       "      <td>0.509671</td>\n",
       "      <td>0.504258</td>\n",
       "      <td>0.495220</td>\n",
       "      <td>0.475620</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.433723</td>\n",
       "      <td>0.575535</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.394635</td>\n",
       "      <td>0.583378</td>\n",
       "      <td>0.025462</td>\n",
       "      <td>0.441396</td>\n",
       "      <td>0.572805</td>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.463837</td>\n",
       "      <td>0.612209</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>0.431086</td>\n",
       "      <td>0.605124</td>\n",
       "      <td>0.068349</td>\n",
       "      <td>0.384521</td>\n",
       "      <td>0.659154</td>\n",
       "      <td>0.076671</td>\n",
       "      <td>0.364080</td>\n",
       "      <td>0.675204</td>\n",
       "      <td>0.087561</td>\n",
       "      <td>0.336053</td>\n",
       "      <td>0.695457</td>\n",
       "      <td>0.083766</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.698485</td>\n",
       "      <td>0.475182</td>\n",
       "      <td>0.306073</td>\n",
       "      <td>0.335168</td>\n",
       "      <td>0.271833</td>\n",
       "      <td>0.414909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12497.500000</td>\n",
       "      <td>1032.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.100050e+06</td>\n",
       "      <td>15.226509</td>\n",
       "      <td>14.472772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.923386</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.481456</td>\n",
       "      <td>203130.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.683721</td>\n",
       "      <td>5135.500000</td>\n",
       "      <td>432.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>867.000000</td>\n",
       "      <td>1884.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.852247</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>27.588889</td>\n",
       "      <td>12.231108</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>6.312500</td>\n",
       "      <td>3.190896</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.235223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.315483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.894440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.951800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>1.921538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>2.064882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.151844</td>\n",
       "      <td>0.460018</td>\n",
       "      <td>14.054528</td>\n",
       "      <td>15.896451</td>\n",
       "      <td>14.345639</td>\n",
       "      <td>0.782257</td>\n",
       "      <td>12.363081</td>\n",
       "      <td>15.536043</td>\n",
       "      <td>13.344313</td>\n",
       "      <td>1.492207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.028939</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>6250.047381</td>\n",
       "      <td>24999.975024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>6249.376093</td>\n",
       "      <td>25000.052334</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-0.073704</td>\n",
       "      <td>4.405457e-02</td>\n",
       "      <td>2.854565e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.054520</td>\n",
       "      <td>-0.111474</td>\n",
       "      <td>-0.179784</td>\n",
       "      <td>1.906685e-01</td>\n",
       "      <td>0.256835</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-2.884872e-01</td>\n",
       "      <td>-0.267281</td>\n",
       "      <td>-0.084103</td>\n",
       "      <td>-3.656193e-01</td>\n",
       "      <td>-0.483078</td>\n",
       "      <td>0.428174</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-2.886775e-01</td>\n",
       "      <td>-3.015285e-01</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.558459</td>\n",
       "      <td>0.570673</td>\n",
       "      <td>0.561762</td>\n",
       "      <td>0.540892</td>\n",
       "      <td>0.561987</td>\n",
       "      <td>0.563452</td>\n",
       "      <td>0.563690</td>\n",
       "      <td>0.570242</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>0.485071</td>\n",
       "      <td>0.612189</td>\n",
       "      <td>0.051646</td>\n",
       "      <td>0.450675</td>\n",
       "      <td>0.645144</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>0.486292</td>\n",
       "      <td>0.657963</td>\n",
       "      <td>0.049395</td>\n",
       "      <td>0.489674</td>\n",
       "      <td>0.657036</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>0.452389</td>\n",
       "      <td>0.617945</td>\n",
       "      <td>0.077410</td>\n",
       "      <td>0.425746</td>\n",
       "      <td>0.681987</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>0.414530</td>\n",
       "      <td>0.702696</td>\n",
       "      <td>0.101993</td>\n",
       "      <td>0.389780</td>\n",
       "      <td>0.725237</td>\n",
       "      <td>0.107874</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.670975</td>\n",
       "      <td>0.441284</td>\n",
       "      <td>0.393864</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.481120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13994.250000</td>\n",
       "      <td>1159.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.037800e+07</td>\n",
       "      <td>16.155199</td>\n",
       "      <td>15.455987</td>\n",
       "      <td>11.931642</td>\n",
       "      <td>14.756884</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>28.358838</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>213845.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>43.100000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>8199.750000</td>\n",
       "      <td>904.000000</td>\n",
       "      <td>814.500000</td>\n",
       "      <td>1798.250000</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.404293</td>\n",
       "      <td>2750.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>45.777778</td>\n",
       "      <td>20.703004</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>7.071429</td>\n",
       "      <td>3.476109</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.937500</td>\n",
       "      <td>3.544588</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.769231</td>\n",
       "      <td>3.600505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>2.931823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>2.845318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.985669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>16.072222</td>\n",
       "      <td>1.013815</td>\n",
       "      <td>15.729905</td>\n",
       "      <td>16.593646</td>\n",
       "      <td>15.190777</td>\n",
       "      <td>3.406070</td>\n",
       "      <td>14.036252</td>\n",
       "      <td>16.154738</td>\n",
       "      <td>14.256633</td>\n",
       "      <td>4.648235</td>\n",
       "      <td>12.230770</td>\n",
       "      <td>15.556173</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>11111.192136</td>\n",
       "      <td>33333.297233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>11111.118832</td>\n",
       "      <td>33333.167521</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>0.710985</td>\n",
       "      <td>8.775575e-01</td>\n",
       "      <td>8.888420e-01</td>\n",
       "      <td>8.759770e-01</td>\n",
       "      <td>8.366600e-01</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>0.752008</td>\n",
       "      <td>0.718243</td>\n",
       "      <td>6.910513e-01</td>\n",
       "      <td>0.665359</td>\n",
       "      <td>0.608526</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>2.389193e-01</td>\n",
       "      <td>0.790240</td>\n",
       "      <td>0.512790</td>\n",
       "      <td>1.034815e+00</td>\n",
       "      <td>1.044466</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.242667e-01</td>\n",
       "      <td>-9.133727e-02</td>\n",
       "      <td>1022.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605390</td>\n",
       "      <td>0.638812</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>0.609921</td>\n",
       "      <td>0.575696</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>0.622356</td>\n",
       "      <td>0.631074</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.053532</td>\n",
       "      <td>0.524667</td>\n",
       "      <td>0.645453</td>\n",
       "      <td>0.066607</td>\n",
       "      <td>0.522488</td>\n",
       "      <td>0.662910</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.490250</td>\n",
       "      <td>0.683716</td>\n",
       "      <td>0.063215</td>\n",
       "      <td>0.552556</td>\n",
       "      <td>0.670516</td>\n",
       "      <td>0.058837</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>0.632533</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.461898</td>\n",
       "      <td>0.706466</td>\n",
       "      <td>0.101355</td>\n",
       "      <td>0.447552</td>\n",
       "      <td>0.739167</td>\n",
       "      <td>0.118086</td>\n",
       "      <td>0.435722</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.137282</td>\n",
       "      <td>0.448671</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.739357</td>\n",
       "      <td>0.531257</td>\n",
       "      <td>0.576612</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.526992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15893.000000</td>\n",
       "      <td>1317.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.348588e+08</td>\n",
       "      <td>19.274495</td>\n",
       "      <td>18.809009</td>\n",
       "      <td>17.268984</td>\n",
       "      <td>18.497077</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4175.000000</td>\n",
       "      <td>54.504522</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>346350.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>9550.000000</td>\n",
       "      <td>4350.000000</td>\n",
       "      <td>999.00000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>254.600000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>252.700000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>11939.000000</td>\n",
       "      <td>2909.000000</td>\n",
       "      <td>2249.000000</td>\n",
       "      <td>3355.000000</td>\n",
       "      <td>7433.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.815512</td>\n",
       "      <td>4700.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>92.375000</td>\n",
       "      <td>70.435854</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>8.727273</td>\n",
       "      <td>4.136863</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>4.367085</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.818182</td>\n",
       "      <td>4.713203</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.338539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.214286</td>\n",
       "      <td>9.227977</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.214286</td>\n",
       "      <td>6.875076</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.923077</td>\n",
       "      <td>7.827303</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.240755</td>\n",
       "      <td>6.916644</td>\n",
       "      <td>17.330453</td>\n",
       "      <td>19.274495</td>\n",
       "      <td>16.992847</td>\n",
       "      <td>8.114363</td>\n",
       "      <td>16.188741</td>\n",
       "      <td>18.809009</td>\n",
       "      <td>16.649854</td>\n",
       "      <td>7.975289</td>\n",
       "      <td>15.554572</td>\n",
       "      <td>18.497077</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>46278.043507</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>53846.214103</td>\n",
       "      <td>51887.416346</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>53845.917692</td>\n",
       "      <td>51887.726210</td>\n",
       "      <td>-0.638710</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>2.335946e+00</td>\n",
       "      <td>2.149121e+00</td>\n",
       "      <td>2.455807e+00</td>\n",
       "      <td>1.592196e+00</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>2.409158e+00</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>4.006933e+00</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>3.105677</td>\n",
       "      <td>3.541888e+00</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>4.006938e+00</td>\n",
       "      <td>4.006938e+00</td>\n",
       "      <td>9550.000000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.806999</td>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.752973</td>\n",
       "      <td>0.685222</td>\n",
       "      <td>0.810379</td>\n",
       "      <td>0.887247</td>\n",
       "      <td>0.956067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103884</td>\n",
       "      <td>0.694092</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.125912</td>\n",
       "      <td>0.662910</td>\n",
       "      <td>0.806999</td>\n",
       "      <td>0.151507</td>\n",
       "      <td>0.693418</td>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.707466</td>\n",
       "      <td>0.752973</td>\n",
       "      <td>0.081742</td>\n",
       "      <td>0.515771</td>\n",
       "      <td>0.685222</td>\n",
       "      <td>0.134915</td>\n",
       "      <td>0.547820</td>\n",
       "      <td>0.810379</td>\n",
       "      <td>0.156024</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.887247</td>\n",
       "      <td>0.184638</td>\n",
       "      <td>0.559186</td>\n",
       "      <td>0.956067</td>\n",
       "      <td>0.267438</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867251</td>\n",
       "      <td>0.748280</td>\n",
       "      <td>0.788763</td>\n",
       "      <td>0.687492</td>\n",
       "      <td>0.697808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      race_id          age          num   race_count  \\\n",
       "count   3080.000000  3080.000000  3080.000000  3080.000000  3080.000000   \n",
       "mean   12058.309740   995.287662     5.892208     7.043506    31.653247   \n",
       "std     2559.063269   216.376235     1.938165     4.064684    28.738711   \n",
       "min     4991.000000   404.000000     3.000000     1.000000     0.000000   \n",
       "25%    10281.750000   843.000000     4.000000     4.000000    10.000000   \n",
       "50%    12497.500000  1032.000000     5.000000     7.000000    24.000000   \n",
       "75%    13994.250000  1159.000000     7.000000    10.000000    47.000000   \n",
       "max    15893.000000  1317.000000    14.000000    18.000000   287.000000   \n",
       "\n",
       "       victory_count  placed_count  placed_2_count  placed_3_count  \\\n",
       "count    3080.000000   3080.000000     3080.000000     3080.000000   \n",
       "mean        3.504221     14.121104        3.234416        2.990260   \n",
       "std         3.835525     13.266399        3.327855        3.177938   \n",
       "min         0.000000      0.000000        0.000000        0.000000   \n",
       "25%         1.000000      4.000000        1.000000        1.000000   \n",
       "50%         2.000000     11.000000        2.000000        2.000000   \n",
       "75%         5.000000     21.000000        5.000000        5.000000   \n",
       "max        29.000000     84.000000       29.000000       32.000000   \n",
       "\n",
       "           earnings  victory_earnings  placed_earnings  year_earnings  \\\n",
       "count  3.080000e+03       3080.000000      3080.000000    3080.000000   \n",
       "mean   8.205089e+06         14.697742        13.154541       4.894091   \n",
       "std    1.303455e+07          2.838504         4.403119       6.074194   \n",
       "min    0.000000e+00          0.000000         0.000000       0.000000   \n",
       "25%    1.391350e+06         14.145786        13.231892       0.000000   \n",
       "50%    4.100050e+06         15.226509        14.472772       0.000000   \n",
       "75%    1.037800e+07         16.155199        15.455987      11.931642   \n",
       "max    2.348588e+08         19.274495        18.809009      17.268984   \n",
       "\n",
       "       prev_year_earnings  post_position     position  handicap_weight  \\\n",
       "count         3080.000000    3080.000000  2468.000000      3080.000000   \n",
       "mean            11.973591       7.043506     5.974068         7.366883   \n",
       "std              5.057159       4.064684     3.606413        13.698126   \n",
       "min              0.000000       1.000000     1.000000         0.000000   \n",
       "25%             12.435196       4.000000     3.000000         0.000000   \n",
       "50%             13.923386       7.000000     6.000000         0.000000   \n",
       "75%             14.756884      10.000000     8.000000         6.250000   \n",
       "max             18.497077      18.000000    18.000000        63.000000   \n",
       "\n",
       "       handicap_distance  trueskill_mu  trueskill_sigma           time  \\\n",
       "count        3080.000000   3080.000000      3080.000000    1479.000000   \n",
       "mean         1646.099026     25.632188         4.491025  194437.728195   \n",
       "std          1261.282374      6.916171         2.533135   28408.918957   \n",
       "min             0.000000      1.529207         1.038827  119900.000000   \n",
       "25%             0.000000     21.036082         2.393291  166625.000000   \n",
       "50%          2150.000000     25.000000         3.481456  203130.000000   \n",
       "75%          2700.000000     28.358838         8.333333  213845.000000   \n",
       "max          4175.000000     54.504522         8.333333  346350.000000   \n",
       "\n",
       "         hist_1_days    hist_2_days    hist_3_days  winner_dividend  \\\n",
       "count    3080.000000    3080.000000    3080.000000      3080.000000   \n",
       "mean    32119.038961   85587.057468   98279.605844        71.347403   \n",
       "std     46691.693698   35124.033872   13003.694215       408.748718   \n",
       "min         1.000000       6.000000      13.000000         0.000000   \n",
       "25%        11.000000  100000.000000  100000.000000         0.000000   \n",
       "50%        16.000000  100000.000000  100000.000000         0.000000   \n",
       "75%    100000.000000  100000.000000  100000.000000         0.000000   \n",
       "max    100000.000000  100000.000000  100000.000000      9550.000000   \n",
       "\n",
       "       placed_dividend  final_odds  final_odds_offline  final_odds_unibet  \\\n",
       "count      3080.000000  3006.00000         2788.000000        2818.000000   \n",
       "mean         70.373377    37.40316           35.473350          35.558588   \n",
       "std         181.711819    53.71988           44.129618          44.798292   \n",
       "min           0.000000     1.10000            1.100000           1.100000   \n",
       "25%           0.000000     7.70000            7.700000           7.600000   \n",
       "50%           0.000000    18.00000           18.000000          17.650000   \n",
       "75%           0.000000    44.00000           45.000000          43.100000   \n",
       "max        4350.000000   999.00000          334.000000         254.600000   \n",
       "\n",
       "       final_odds_ref  final_odds_ref_offline  final_odds_ref_unibet  \\\n",
       "count     3080.000000             3080.000000            2837.000000   \n",
       "mean      3044.738344            10572.729610              31.064152   \n",
       "std      17110.659985            30720.020377              38.953914   \n",
       "min          1.200000                1.100000               1.100000   \n",
       "25%          8.200000                8.675000               7.900000   \n",
       "50%         16.000000               17.000000              16.700000   \n",
       "75%         32.000000               38.000000              36.100000   \n",
       "max     100000.000000           100000.000000             252.700000   \n",
       "\n",
       "       trainer_winning_rate  trainer_avg_winning_dividend      horse_id  \\\n",
       "count           3080.000000                   3080.000000   3080.000000   \n",
       "mean            7565.010366                   7564.709614   5352.513312   \n",
       "std            26447.896556                  26447.982695   3434.899283   \n",
       "min                0.000000                     -1.000000      1.000000   \n",
       "25%                0.000000                     -1.000000   2448.750000   \n",
       "50%                0.055556                     -0.683721   5135.500000   \n",
       "75%                0.150000                      0.180000   8199.750000   \n",
       "max           100000.000000                 100000.000000  11939.000000   \n",
       "\n",
       "        trainer_id    jockey_id    herder_id     owner_id     num_race  \\\n",
       "count  3080.000000  3080.000000  2544.000000  3080.000000  3080.000000   \n",
       "mean    659.813961   561.243506  1143.316431  2434.752922     4.701948   \n",
       "std     667.244766   558.509603   942.329141  2092.263536     2.433019   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%     175.000000   138.000000   346.500000   634.750000     3.000000   \n",
       "50%     432.000000   385.000000   867.000000  1884.500000     5.000000   \n",
       "75%     904.000000   814.500000  1798.250000  3739.000000     7.000000   \n",
       "max    2909.000000  2249.000000  3355.000000  7433.000000    11.000000   \n",
       "\n",
       "          num_bis        prize     distance  declared_player_count  \\\n",
       "count  312.000000  3080.000000  3080.000000            3080.000000   \n",
       "mean     2.003205     9.800963  2354.245130              13.087013   \n",
       "std      0.811883     0.994653   610.204077               2.642661   \n",
       "min      1.000000     7.093405  1000.000000               5.000000   \n",
       "25%      1.000000     9.546884  2100.000000              11.000000   \n",
       "50%      2.000000     9.852247  2400.000000              13.000000   \n",
       "75%      2.000000    10.404293  2750.000000              15.000000   \n",
       "max      4.000000    13.815512  4700.000000              18.000000   \n",
       "\n",
       "        session_id  num_session  hippodrome_id   hist_1_pos   hist_2_pos  \\\n",
       "count  3080.000000  3080.000000    3080.000000  3080.000000  3080.000000   \n",
       "mean    144.403571     3.099351       9.421429     6.238961     6.112013   \n",
       "std      30.848125     2.034263      11.479637     3.241704     3.309928   \n",
       "min      59.000000     1.000000       1.000000     1.000000     0.000000   \n",
       "25%     123.000000     1.000000       1.000000     3.000000     3.000000   \n",
       "50%     150.000000     3.000000       3.000000     6.000000     6.000000   \n",
       "75%     168.000000     4.000000      14.000000    10.000000    10.000000   \n",
       "max     188.000000     9.000000      51.000000    10.000000    10.000000   \n",
       "\n",
       "        hist_3_pos   hist_4_pos   hist_5_pos   hist_6_pos        speed  \\\n",
       "count  3080.000000  3080.000000  3080.000000  3080.000000  3080.000000   \n",
       "mean      5.913961     5.475325     5.113961     4.805195     0.006353   \n",
       "std       3.396127     3.594686     3.654670     3.762308     0.006616   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     0.000000   \n",
       "50%       6.000000     5.000000     5.000000     4.000000     0.000000   \n",
       "75%      10.000000    10.000000     9.000000     9.000000     0.013219   \n",
       "max      10.000000    10.000000    10.000000    10.000000     0.014132   \n",
       "\n",
       "               win  final_odds_ref_inv  race_count_mean  race_count_std  \\\n",
       "count  3080.000000         3080.000000      3080.000000     3080.000000   \n",
       "mean      0.080195            0.096572        31.653247       14.165818   \n",
       "std       0.271639            0.103615        22.684714       11.616015   \n",
       "min       0.000000            0.000000         0.000000        0.000000   \n",
       "25%       0.000000            0.031250        12.666667        5.434876   \n",
       "50%       0.000000            0.062500        27.588889       12.231108   \n",
       "75%       0.000000            0.121951        45.777778       20.703004   \n",
       "max       1.000000            0.833333        92.375000       70.435854   \n",
       "\n",
       "       race_count_amin  race_count_amax  hist_1_pos_mean  hist_1_pos_std  \\\n",
       "count      3080.000000      3080.000000      3080.000000     3080.000000   \n",
       "mean         11.997727        60.481818         6.238961        3.148605   \n",
       "std          12.849227        47.366417         1.089158        0.468166   \n",
       "min           0.000000         0.000000         3.090909        1.509231   \n",
       "25%           2.000000        25.000000         5.444444        2.875627   \n",
       "50%           8.000000        53.000000         6.312500        3.190896   \n",
       "75%          18.000000        89.000000         7.071429        3.476109   \n",
       "max          64.000000       287.000000         8.727273        4.136863   \n",
       "\n",
       "       hist_1_pos_amin  hist_1_pos_amax  hist_2_pos_mean  hist_2_pos_std  \\\n",
       "count      3080.000000      3080.000000      3080.000000     3080.000000   \n",
       "mean          1.435714         9.937987         6.112013        3.216126   \n",
       "std           0.793214         0.348129         1.111378        0.470053   \n",
       "min           1.000000         6.000000         3.000000        1.589899   \n",
       "25%           1.000000        10.000000         5.375000        2.906367   \n",
       "50%           1.000000        10.000000         6.200000        3.235223   \n",
       "75%           2.000000        10.000000         6.937500        3.544588   \n",
       "max           6.000000        10.000000         9.200000        4.367085   \n",
       "\n",
       "       hist_2_pos_amin  hist_2_pos_amax  hist_3_pos_mean  hist_3_pos_std  \\\n",
       "count      3080.000000      3080.000000      3080.000000     3080.000000   \n",
       "mean          1.286364         9.934091         5.913961        3.278834   \n",
       "std           0.809458         0.349277         1.186885        0.507270   \n",
       "min           0.000000         7.000000         1.133333        1.615893   \n",
       "25%           1.000000        10.000000         5.153846        3.002887   \n",
       "50%           1.000000        10.000000         6.000000        3.315483   \n",
       "75%           2.000000        10.000000         6.769231        3.600505   \n",
       "max           5.000000        10.000000         8.818182        4.713203   \n",
       "\n",
       "       hist_3_pos_amin  hist_3_pos_amax  post_position_mean  \\\n",
       "count      3080.000000      3080.000000         3080.000000   \n",
       "mean          1.159416         9.865584            7.043506   \n",
       "std           0.719227         0.621774            1.321331   \n",
       "min           0.000000         5.000000            3.000000   \n",
       "25%           1.000000        10.000000            6.000000   \n",
       "50%           1.000000        10.000000            7.000000   \n",
       "75%           1.000000        10.000000            8.000000   \n",
       "max           4.000000        10.000000            9.500000   \n",
       "\n",
       "       post_position_std  post_position_amin  post_position_amax  \\\n",
       "count        3080.000000              3080.0         3080.000000   \n",
       "mean            3.919455                 1.0           13.087013   \n",
       "std             0.763490                 0.0            2.642661   \n",
       "min             1.581139                 1.0            5.000000   \n",
       "25%             3.316625                 1.0           11.000000   \n",
       "50%             3.894440                 1.0           13.000000   \n",
       "75%             4.472136                 1.0           15.000000   \n",
       "max             5.338539                 1.0           18.000000   \n",
       "\n",
       "       victory_count_mean  victory_count_std  victory_count_amin  \\\n",
       "count         3080.000000        3080.000000         3080.000000   \n",
       "mean             3.504221           2.126733            0.711688   \n",
       "std              2.919996           1.473349            1.337735   \n",
       "min              0.000000           0.000000            0.000000   \n",
       "25%              1.222222           1.029857            0.000000   \n",
       "50%              3.000000           1.951800            0.000000   \n",
       "75%              4.857143           2.931823            1.000000   \n",
       "max             13.214286           9.227977            8.000000   \n",
       "\n",
       "       victory_count_amax  placed_2_count_mean  placed_2_count_std  \\\n",
       "count         3080.000000          3080.000000         3080.000000   \n",
       "mean             7.838961             3.234416            2.086545   \n",
       "std              5.843030             2.339350            1.303400   \n",
       "min              0.000000             0.000000            0.000000   \n",
       "25%              3.000000             1.384615            1.103713   \n",
       "50%              7.000000             2.909091            1.921538   \n",
       "75%             11.000000             4.750000            2.845318   \n",
       "max             29.000000             9.214286            6.875076   \n",
       "\n",
       "       placed_2_count_amin  placed_2_count_amax  placed_3_count_mean  \\\n",
       "count          3080.000000          3080.000000          3080.000000   \n",
       "mean              0.557468             7.471104             2.990260   \n",
       "std               0.983433             5.147119             2.073357   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             3.000000             1.285714   \n",
       "50%               0.000000             7.000000             2.727273   \n",
       "75%               1.000000            10.000000             4.500000   \n",
       "max               4.000000            29.000000             8.923077   \n",
       "\n",
       "       placed_3_count_std  placed_3_count_amin  placed_3_count_amax  \\\n",
       "count         3080.000000          3080.000000          3080.000000   \n",
       "mean             2.147648             0.427922             7.599675   \n",
       "std              1.286259             0.807966             5.139288   \n",
       "min              0.000000             0.000000             0.000000   \n",
       "25%              1.182132             0.000000             4.000000   \n",
       "50%              2.064882             0.000000             7.000000   \n",
       "75%              2.985669             1.000000            11.000000   \n",
       "max              7.827303             4.000000            32.000000   \n",
       "\n",
       "       victory_earnings_mean  victory_earnings_std  victory_earnings_amin  \\\n",
       "count            3080.000000           3080.000000            3080.000000   \n",
       "mean               14.697742              1.074520              12.545733   \n",
       "std                 2.155155              1.610606               4.901551   \n",
       "min                 4.107691              0.033033               0.000000   \n",
       "25%                14.028098              0.209101              11.867104   \n",
       "50%                15.151844              0.460018              14.054528   \n",
       "75%                16.072222              1.013815              15.729905   \n",
       "max                18.240755              6.916644              17.330453   \n",
       "\n",
       "       victory_earnings_amax  placed_earnings_mean  placed_earnings_std  \\\n",
       "count            3080.000000           3080.000000          3080.000000   \n",
       "mean               15.798547             13.154541             1.779444   \n",
       "std                 1.196490              3.584105             1.998147   \n",
       "min                11.642207              0.000000             0.000000   \n",
       "25%                15.102012             12.828576             0.444466   \n",
       "50%                15.896451             14.345639             0.782257   \n",
       "75%                16.593646             15.190777             3.406070   \n",
       "max                19.274495             16.992847             8.114363   \n",
       "\n",
       "       placed_earnings_amin  placed_earnings_amax  prev_year_earnings_mean  \\\n",
       "count           3080.000000           3080.000000              3080.000000   \n",
       "mean               9.234344             14.797916                11.973591   \n",
       "std                6.235615              3.199101                 3.709751   \n",
       "min                0.000000              0.000000                 0.000000   \n",
       "25%                0.000000             14.562389                11.206963   \n",
       "50%               12.363081             15.536043                13.344313   \n",
       "75%               14.036252             16.154738                14.256633   \n",
       "max               16.188741             18.809009                16.649854   \n",
       "\n",
       "       prev_year_earnings_std  prev_year_earnings_amin  \\\n",
       "count             3080.000000              3080.000000   \n",
       "mean                 2.781866                 5.813754   \n",
       "std                  2.264807                 6.243228   \n",
       "min                  0.000000                 0.000000   \n",
       "25%                  0.706875                 0.000000   \n",
       "50%                  1.492207                 0.000000   \n",
       "75%                  4.648235                12.230770   \n",
       "max                  7.975289                15.554572   \n",
       "\n",
       "       prev_year_earnings_amax  ...  hist_2_days_amax  hist_3_days_mean  \\\n",
       "count              3080.000000  ...            3080.0       3080.000000   \n",
       "mean                 14.310481  ...          100000.0      98279.605844   \n",
       "std                   3.240508  ...               0.0       4098.090774   \n",
       "min                   0.000000  ...          100000.0      75004.333333   \n",
       "25%                  14.333710  ...          100000.0     100000.000000   \n",
       "50%                  15.028939  ...          100000.0     100000.000000   \n",
       "75%                  15.556173  ...          100000.0     100000.000000   \n",
       "max                  18.497077  ...          100000.0     100000.000000   \n",
       "\n",
       "       hist_3_days_std  hist_3_days_amin  hist_3_days_amax  \\\n",
       "count      3080.000000       3080.000000            3080.0   \n",
       "mean       5442.977618      81530.091883          100000.0   \n",
       "std       11673.132329      38806.321049               0.0   \n",
       "min           0.000000         13.000000          100000.0   \n",
       "25%           0.000000     100000.000000          100000.0   \n",
       "50%           0.000000     100000.000000          100000.0   \n",
       "75%           0.000000     100000.000000          100000.0   \n",
       "max       46278.043507     100000.000000          100000.0   \n",
       "\n",
       "       trainer_winning_rate_mean  trainer_winning_rate_std  \\\n",
       "count                3080.000000               3080.000000   \n",
       "mean                 7565.010366              17906.921593   \n",
       "std                 10129.596614              18094.486031   \n",
       "min                     0.020353                  0.029164   \n",
       "25%                     0.078318                  0.086327   \n",
       "50%                  6250.047381              24999.975024   \n",
       "75%                 11111.192136              33333.297233   \n",
       "max                 53846.214103              51887.416346   \n",
       "\n",
       "       trainer_winning_rate_amin  trainer_winning_rate_amax  \\\n",
       "count                3080.000000                3080.000000   \n",
       "mean                    0.000412               52370.273637   \n",
       "std                     0.004116               49951.752210   \n",
       "min                     0.000000                   0.076923   \n",
       "25%                     0.000000                   0.250000   \n",
       "50%                     0.000000              100000.000000   \n",
       "75%                     0.000000              100000.000000   \n",
       "max                     0.055556              100000.000000   \n",
       "\n",
       "       trainer_avg_winning_dividend_mean  trainer_avg_winning_dividend_std  \\\n",
       "count                        3080.000000                       3080.000000   \n",
       "mean                         7564.709614                      17907.568017   \n",
       "std                         10129.601796                      18093.979356   \n",
       "min                            -0.869298                          0.267609   \n",
       "25%                            -0.325295                          0.801566   \n",
       "50%                          6249.376093                      25000.052334   \n",
       "75%                         11111.118832                      33333.167521   \n",
       "max                         53845.917692                      51887.726210   \n",
       "\n",
       "       trainer_avg_winning_dividend_amin  trainer_avg_winning_dividend_amax  \\\n",
       "count                        3080.000000                        3080.000000   \n",
       "mean                           -0.997956                       52371.675985   \n",
       "std                             0.021959                       49950.281755   \n",
       "min                            -1.000000                          -0.293750   \n",
       "25%                            -1.000000                           1.500000   \n",
       "50%                            -1.000000                      100000.000000   \n",
       "75%                            -1.000000                      100000.000000   \n",
       "max                            -0.638710                      100000.000000   \n",
       "\n",
       "        race_count_r  hist_1_pos_r  hist_2_pos_r  hist_3_pos_r  \\\n",
       "count    3080.000000  3.080000e+03  3.080000e+03  3.080000e+03   \n",
       "mean     3311.688312  1.730218e-18 -1.297663e-18 -8.506904e-18   \n",
       "std     17897.082106  9.592205e-01  9.592205e-01  9.592205e-01   \n",
       "min        -2.807533 -2.879000e+00 -2.948482e+00 -2.746313e+00   \n",
       "25%        -0.680766 -8.270520e-01 -8.437163e-01 -8.469199e-01   \n",
       "50%        -0.073704  4.405457e-02  2.854565e-02  0.000000e+00   \n",
       "75%         0.710985  8.775575e-01  8.888420e-01  8.759770e-01   \n",
       "max    100000.000000  2.335946e+00  2.149121e+00  2.455807e+00   \n",
       "\n",
       "       post_position_r  victory_count_r  placed_2_count_r  placed_3_count_r  \\\n",
       "count     3.080000e+03      3080.000000       3080.000000       3080.000000   \n",
       "mean     -8.651089e-19      7142.857143       4350.649351       3993.506494   \n",
       "std       9.592205e-01     25758.119551      20402.743428      19583.847372   \n",
       "min      -1.592196e+00        -2.428288         -2.391971         -2.205344   \n",
       "25%      -8.366600e-01        -0.651570         -0.666667         -0.682721   \n",
       "50%       0.000000e+00        -0.054520         -0.111474         -0.179784   \n",
       "75%       8.366600e-01         0.843274          0.752008          0.718243   \n",
       "max       1.592196e+00    100000.000000     100000.000000     100000.000000   \n",
       "\n",
       "       victory_earnings_r  placed_earnings_r  prev_year_earnings_r  \\\n",
       "count        3.080000e+03        3080.000000           3080.000000   \n",
       "mean         2.511699e-16        3993.506494           4448.051948   \n",
       "std          9.592205e-01       19583.847372          20619.361481   \n",
       "min         -3.556379e+00          -3.945335             -3.907250   \n",
       "25%         -5.917605e-01          -0.425542             -0.286117   \n",
       "50%          1.906685e-01           0.256835              0.314381   \n",
       "75%          6.910513e-01           0.665359              0.608526   \n",
       "max          2.409158e+00      100000.000000         100000.000000   \n",
       "\n",
       "       handicap_distance_r  handicap_weight_r  final_odds_ref_r  \\\n",
       "count          3080.000000        3080.000000      3.080000e+03   \n",
       "mean          87305.194805       71136.363636      8.939458e-18   \n",
       "std           33296.882774       45320.205096      9.592205e-01   \n",
       "min              -1.417835          -3.277191     -2.009616e+00   \n",
       "25%          100000.000000           1.044738     -5.765344e-01   \n",
       "50%          100000.000000      100000.000000     -2.884872e-01   \n",
       "75%          100000.000000      100000.000000      2.389193e-01   \n",
       "max          100000.000000      100000.000000      4.006933e+00   \n",
       "\n",
       "       final_odds_ref_offline_r  trueskill_mu_r  trueskill_sigma_r  \\\n",
       "count               3080.000000     3080.000000       3.080000e+03   \n",
       "mean                8181.818182        0.000394      -1.777799e-16   \n",
       "std                27413.202266        0.958534       9.592205e-01   \n",
       "min                   -1.831291       -3.637018      -2.889538e+00   \n",
       "25%                   -0.594489       -0.670365      -7.682838e-01   \n",
       "50%                   -0.267281       -0.084103      -3.656193e-01   \n",
       "75%                    0.790240        0.512790       1.034815e+00   \n",
       "max               100000.000000        3.105677       3.541888e+00   \n",
       "\n",
       "       hist_1_days_r  hist_2_days_r  hist_3_days_r  trainer_winning_rate_r  \\\n",
       "count    3080.000000    3080.000000    3080.000000            3.080000e+03   \n",
       "mean     1071.428571   25032.467532   81525.974026            1.023712e-17   \n",
       "std     10297.054141   43327.033294   38814.972864            9.592205e-01   \n",
       "min        -2.253203      -4.006938      -4.006938           -1.778568e+00   \n",
       "25%        -0.718238       0.277350  100000.000000           -5.262352e-01   \n",
       "50%        -0.483078       0.428174  100000.000000           -2.886775e-01   \n",
       "75%         1.044466  100000.000000  100000.000000            1.242667e-01   \n",
       "max    100000.000000  100000.000000  100000.000000            4.006938e+00   \n",
       "\n",
       "       trainer_avg_winning_dividend_r  race_winner_dividend       odds_0  \\\n",
       "count                    3.080000e+03           3080.000000  3080.000000   \n",
       "mean                    -7.641795e-18            926.224026     3.363117   \n",
       "std                      9.592205e-01           1167.476575     1.202791   \n",
       "min                     -1.630330e+00            110.000000     1.200000   \n",
       "25%                     -5.032489e-01            320.000000     2.500000   \n",
       "50%                     -3.015285e-01            540.000000     3.300000   \n",
       "75%                     -9.133727e-02           1022.500000     4.000000   \n",
       "max                      4.006938e+00           9550.000000     7.300000   \n",
       "\n",
       "            odds_1       odds_2       odds_3       odds_4         odds_5  \\\n",
       "count  3080.000000  3080.000000  3080.000000  3080.000000    3080.000000   \n",
       "mean      5.485487     7.339188     9.524123    11.848052     371.631039   \n",
       "std       1.503116     2.194979     2.756745     3.543852    5965.565224   \n",
       "min       2.600000     3.500000     4.900000     5.000000       7.900000   \n",
       "25%       4.300000     5.900000     7.700000     9.800000      11.000000   \n",
       "50%       5.300000     6.900000     9.100000    11.000000      13.000000   \n",
       "75%       6.400000     8.300000    10.000000    13.000000      17.000000   \n",
       "max      12.000000    23.000000    26.000000    37.000000  100000.000000   \n",
       "\n",
       "              odds_6         odds_7         odds_8         odds_9  \\\n",
       "count    3080.000000    3080.000000    3080.000000    3080.000000   \n",
       "mean     1641.440617    3560.546753    8077.492532   12920.700325   \n",
       "std     12637.071224   18475.118646   27206.435774   33501.976746   \n",
       "min         8.600000      10.000000      11.000000      13.000000   \n",
       "25%        14.000000      16.000000      19.000000      24.000000   \n",
       "50%        16.000000      20.000000      26.000000      32.000000   \n",
       "75%        21.000000      26.000000      33.000000      49.000000   \n",
       "max    100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "\n",
       "             odds_10        odds_11        odds_12        odds_13  \\\n",
       "count    3080.000000    3080.000000    3080.000000    3080.000000   \n",
       "mean    23472.412338   33864.409740   44613.282468   59805.026948   \n",
       "std     42353.106940   47297.431866   49681.500838   49004.232568   \n",
       "min        15.000000      15.000000      16.000000      17.000000   \n",
       "25%        30.750000      40.000000      54.000000      88.000000   \n",
       "50%        41.000000      61.000000     115.000000  100000.000000   \n",
       "75%        96.000000  100000.000000  100000.000000  100000.000000   \n",
       "max    100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "\n",
       "             odds_14        odds_15        odds_16        odds_17   odds_18  \\\n",
       "count    3080.000000    3080.000000    3080.000000    3080.000000    3080.0   \n",
       "mean    68991.280519   82325.050649   94260.474026   96505.358442  100000.0   \n",
       "std     46227.754417   38125.846993   23247.890312   18335.312206       0.0   \n",
       "min        18.000000      36.000000      47.000000      58.000000  100000.0   \n",
       "25%       145.000000  100000.000000  100000.000000  100000.000000  100000.0   \n",
       "50%    100000.000000  100000.000000  100000.000000  100000.000000  100000.0   \n",
       "75%    100000.000000  100000.000000  100000.000000  100000.000000  100000.0   \n",
       "max    100000.000000  100000.000000  100000.000000  100000.000000  100000.0   \n",
       "\n",
       "        odds_19  target_returns       target  target_stacked  pred_nn_1_1  \\\n",
       "count    3080.0     3080.000000  3080.000000     3080.000000  3080.000000   \n",
       "mean   100000.0        0.713474     0.563560        0.014269     0.550192   \n",
       "std         0.0        4.087487     0.313742        0.081750     0.074318   \n",
       "min    100000.0        0.000000     0.055556        0.000000     0.352517   \n",
       "25%    100000.0        0.000000     0.285714        0.000000     0.500941   \n",
       "50%    100000.0        0.000000     0.545455        0.000000     0.555336   \n",
       "75%    100000.0        0.000000     0.866667        0.000000     0.605390   \n",
       "max    100000.0       95.500000     1.000000        1.910000     0.718114   \n",
       "\n",
       "       pred_nn_51_1  pred_nn_101_1  pred_nn_151_1  pred_xgb_10_1  \\\n",
       "count   3080.000000    3080.000000    3080.000000    3080.000000   \n",
       "mean       0.552409       0.561827       0.561101       0.540216   \n",
       "std        0.092798       0.083384       0.068871       0.051841   \n",
       "min        0.378737       0.330463       0.381320       0.368837   \n",
       "25%        0.493679       0.488881       0.508774       0.505955   \n",
       "50%        0.558459       0.570673       0.561762       0.540892   \n",
       "75%        0.638812       0.620710       0.609921       0.575696   \n",
       "max        0.806999       0.825878       0.752973       0.685222   \n",
       "\n",
       "       pred_xgb_30_1  pred_xgb_50_1  pred_xgb_100_1  pred_knn_5_1  \\\n",
       "count    3080.000000    3080.000000     3080.000000   3080.000000   \n",
       "mean        0.560042       0.562125        0.562586      0.567399   \n",
       "std         0.078874       0.090634        0.106629      0.127821   \n",
       "min         0.243548       0.190972        0.145182      0.134545   \n",
       "25%         0.509671       0.504258        0.495220      0.475620   \n",
       "50%         0.561987       0.563452        0.563690      0.570242   \n",
       "75%         0.613534       0.622356        0.631074      0.657143   \n",
       "max         0.810379       0.887247        0.956067      1.000000   \n",
       "\n",
       "       pred_nn_1_std  pred_nn_1_min  pred_nn_1_max  pred_nn_51_std  \\\n",
       "count    3080.000000    3080.000000    3080.000000     3080.000000   \n",
       "mean        0.037659       0.489621       0.603030        0.047199   \n",
       "std         0.024378       0.072614       0.067863        0.029810   \n",
       "min         0.000000       0.352517       0.369244        0.000000   \n",
       "25%         0.018805       0.433723       0.575535        0.027470   \n",
       "50%         0.039158       0.485071       0.612189        0.051646   \n",
       "75%         0.053532       0.524667       0.645453        0.066607   \n",
       "max         0.103884       0.694092       0.718114        0.125912   \n",
       "\n",
       "       pred_nn_51_min  pred_nn_51_max  pred_nn_101_std  pred_nn_101_min  \\\n",
       "count     3080.000000     3080.000000      3080.000000      3080.000000   \n",
       "mean         0.467093        0.614685         0.049794         0.484004   \n",
       "std          0.080194        0.081837         0.032108         0.066928   \n",
       "min          0.378737        0.378737         0.000000         0.330463   \n",
       "25%          0.394635        0.583378         0.025462         0.441396   \n",
       "50%          0.450675        0.645144         0.056357         0.486292   \n",
       "75%          0.522488        0.662910         0.069171         0.490250   \n",
       "max          0.662910        0.806999         0.151507         0.693418   \n",
       "\n",
       "       pred_nn_101_max  pred_nn_151_std  pred_nn_151_min  pred_nn_151_max  \\\n",
       "count      3080.000000      3080.000000      3080.000000      3080.000000   \n",
       "mean          0.636122         0.046356         0.502969         0.637749   \n",
       "std           0.082895         0.024133         0.054724         0.055285   \n",
       "min           0.394664         0.000000         0.381320         0.463837   \n",
       "25%           0.572805         0.031166         0.463837         0.612209   \n",
       "50%           0.657963         0.049395         0.489674         0.657036   \n",
       "75%           0.683716         0.063215         0.552556         0.670516   \n",
       "max           0.825878         0.110323         0.707466         0.752973   \n",
       "\n",
       "       pred_xgb_10_std  pred_xgb_10_min  pred_xgb_10_max  pred_xgb_30_std  \\\n",
       "count      3080.000000      3080.000000      3080.000000      3080.000000   \n",
       "mean          0.051727         0.449214         0.619363         0.078528   \n",
       "std           0.010913         0.031450         0.022323         0.016772   \n",
       "min           0.021732         0.368837         0.560051         0.031180   \n",
       "25%           0.044525         0.431086         0.605124         0.068349   \n",
       "50%           0.051170         0.452389         0.617945         0.077410   \n",
       "75%           0.058837         0.475410         0.632533         0.089700   \n",
       "max           0.081742         0.515771         0.685222         0.134915   \n",
       "\n",
       "       pred_xgb_30_min  pred_xgb_30_max  pred_xgb_50_std  pred_xgb_50_min  \\\n",
       "count      3080.000000      3080.000000      3080.000000      3080.000000   \n",
       "mean          0.421228         0.686230         0.089374         0.405409   \n",
       "std           0.051980         0.037567         0.019706         0.060755   \n",
       "min           0.243548         0.619210         0.036341         0.190972   \n",
       "25%           0.384521         0.659154         0.076671         0.364080   \n",
       "50%           0.425746         0.681987         0.088122         0.414530   \n",
       "75%           0.461898         0.706466         0.101355         0.447552   \n",
       "max           0.547820         0.810379         0.156024         0.550476   \n",
       "\n",
       "       pred_xgb_50_max  pred_xgb_100_std  pred_xgb_100_min  pred_xgb_100_max  \\\n",
       "count      3080.000000       3080.000000       3080.000000       3080.000000   \n",
       "mean          0.708236          0.104170          0.379497          0.735112   \n",
       "std           0.047066          0.023427          0.074537          0.059621   \n",
       "min           0.626898          0.051582          0.145182          0.621927   \n",
       "25%           0.675204          0.087561          0.336053          0.695457   \n",
       "50%           0.702696          0.101993          0.389780          0.725237   \n",
       "75%           0.739167          0.118086          0.435722          0.771154   \n",
       "max           0.887247          0.184638          0.559186          0.956067   \n",
       "\n",
       "       pred_knn_5_std  pred_knn_5_min  pred_knn_5_max  \\\n",
       "count     3080.000000     3080.000000     3080.000000   \n",
       "mean         0.110182        0.389714        0.747217   \n",
       "std          0.039151        0.089916        0.088057   \n",
       "min          0.000000        0.134545        0.450000   \n",
       "25%          0.083766        0.331667        0.698485   \n",
       "50%          0.107874        0.385714        0.742857   \n",
       "75%          0.137282        0.448671        0.807576   \n",
       "max          0.267438        0.625000        1.000000   \n",
       "\n",
       "       pred_stacked_stacked_nn_1_1  pred_stacked_stacked_nn_3_1  \\\n",
       "count                  3080.000000                  3080.000000   \n",
       "mean                      0.615138                     0.424664   \n",
       "std                       0.149019                     0.135086   \n",
       "min                       0.286546                     0.148284   \n",
       "25%                       0.475182                     0.306073   \n",
       "50%                       0.670975                     0.441284   \n",
       "75%                       0.739357                     0.531257   \n",
       "max                       0.867251                     0.748280   \n",
       "\n",
       "       pred_stacked_stacked_nn_5_1  pred_stacked_stacked_nn_7_1  \\\n",
       "count                  3080.000000                  3080.000000   \n",
       "mean                      0.447344                     0.396618   \n",
       "std                       0.140235                     0.143173   \n",
       "min                       0.229626                     0.100132   \n",
       "25%                       0.335168                     0.271833   \n",
       "50%                       0.393864                     0.385375   \n",
       "75%                       0.576612                     0.497311   \n",
       "max                       0.788763                     0.687492   \n",
       "\n",
       "       pred_stacked_stacked_nn_9_1  \n",
       "count                  3080.000000  \n",
       "mean                      0.475507  \n",
       "std                       0.081960  \n",
       "min                       0.281769  \n",
       "25%                       0.414909  \n",
       "50%                       0.481120  \n",
       "75%                       0.526992  \n",
       "max                       0.697808  \n",
       "\n",
       "[8 rows x 231 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program.df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program.model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} samples, {} features'.format(program.df.shape[0], len(program.model.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(program.model, 'stacked_models'):\n",
    "    program.model.stacked_models = []\n",
    "    program.df['target_stacked'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model[\"name\"] for model in program.model.models] + [model[\"name\"] for model in program.model.stacked_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    '{} races from {} to {}'.format(\n",
    "        program.df.race_id.nunique(), \n",
    "        program.df.start_at.min(), \n",
    "        program.df.start_at.max()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in program.model.models:\n",
    "    clf = model['estimators'][-1]['pipeline'].steps[-1][1]\n",
    "    if hasattr(clf, 'classes_'):\n",
    "        clf = model['estimators'][-1]['pipeline'].steps[-1][1]\n",
    "        print(clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cataclop.ml import preprocessing\n",
    "pd.set_option('precision',7)\n",
    "    \n",
    "for model in program.model.models:\n",
    "    clf = model['estimators'][-1]['pipeline'].steps[-1][1]\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        fi = pd.Series(clf.feature_importances_, index=program.model.features+preprocessing.get_dummy_features(model['estimators'][-1]['dummies']))\n",
    "        print(model['name'])\n",
    "        print(fi.sort_values(ascending=False)[0:100])\n",
    "        print(\"---\\n\")\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        fi = pd.Series(clf.coef_, index=program.model.features+preprocessing.get_dummy_features(model['estimators'][-1]['dummies']))\n",
    "        print(model['name'])\n",
    "        print(fi.sort_values(ascending=False)[0:100])\n",
    "        print(\"---\\n\")\n",
    "\n",
    "if hasattr(program.model, \"stacked_models\"):\n",
    "    for model in program.model.stacked_models:\n",
    "        clf = model['estimators'][-1]['pipeline'].steps[-1][1]\n",
    "        if hasattr(clf, 'feature_importances_'):\n",
    "            fi = pd.Series(clf.feature_importances_, index=program.model.stacked_features+preprocessing.get_dummy_features(model['estimators'][-1]['dummies']))\n",
    "            print(model['name'])\n",
    "            print(fi.sort_values(ascending=False)[0:100])\n",
    "            print(\"---\\n\")\n",
    "        if hasattr(clf, 'coef_'):\n",
    "            fi = pd.Series(clf.coef_, index=program.model.stacked_features+preprocessing.get_dummy_features(model['estimators'][-1]['dummies']))\n",
    "            print(model['name'])\n",
    "            print(fi.sort_values(ascending=False)[0:100])\n",
    "            print(\"---\\n\")\n",
    "        \n",
    "pd.set_option('precision',7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = program.df\n",
    "\n",
    "for model in program.model.models:\n",
    "    print(model['name'], df['pred_{}_1'.format(model['name'])].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df['pred_sum_1'] = 1\n",
    "for model in program.model.models:\n",
    "    m = model['name']\n",
    "    #s = preprocessing.MinMaxScaler()\n",
    "    #scaled = s.fit_transform(df[['pred_{}_1'.format(m)]].values)\n",
    "    #df['pred_{}_s_1'.format(m)] = scaled\n",
    "    #df['pred_sum_1'] = df['pred_sum_1'] * df['pred_{}_s_1'.format(m)]\n",
    "    \n",
    "df['pred_sum_1'] = df[['pred_{}_1'.format(model['name']) for model in program.model.models]].sum(axis=1)\n",
    "df['pred_sum_1'] /= len(program.model.models)\n",
    "\n",
    "df['pred_stacked_sum_1'] = df[['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models]].sum(axis=1)\n",
    "df['pred_stacked_sum_1'] /= len(program.model.stacked_models)\n",
    "\n",
    "df['pred_odds_1'] = df['final_odds_ref']\n",
    "df['pred_rnd_1'] = np.random.rand(df.shape[0])\n",
    "df['pred_trueskill_mu_1'] = df['trueskill_mu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "            'position', \n",
    "            'declared_player_count', \n",
    "            'sub_category', \n",
    "            'num', \n",
    "            'final_odds', \n",
    "            'final_odds_ref', \n",
    "            'final_odds_ref_unibet', \n",
    "            'target',\n",
    "            'target_stacked',\n",
    "            'pred_sum_1',\n",
    "            'pred_stacked_sum_1',\n",
    "            'race_winner_dividend',\n",
    "            'winner_dividend',\n",
    "            'placed_dividend',\n",
    "            'trueskill_mu',\n",
    "            'hist_1_pos'\n",
    "        ] + [\n",
    "            'pred_{}_1'.format(model['name']) for model in program.model.models\n",
    "        ] + [\n",
    "            'pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models\n",
    "        ] \n",
    "exploration.random_race(df, \n",
    "                        cols=cols\n",
    "                       ).sort_values(by='position', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more exploration of a single race features\n",
    "#(df.reset_index(drop=True).set_index(['race_id', df.index]).loc[65509][['position'] + program.model.features]).sort_values(by='position', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = program.model.models + [{\"name\": \"sum\"}, {\"name\": \"maj\"}, {\"name\": \"stacked_maj\"}, {\"name\": \"stacked_sum\"}, {\"name\": \"rnd\"}, {\"name\": \"odds\"}, {\"name\": \"trueskill_mu\"}]\n",
    "#dd = df.groupby('race_id').filter(lambda r: r['pred_sum'].std()!=0)\n",
    "models = models + [{\"name\": \"stacked_{}\".format(model[\"name\"])} for model in program.model.stacked_models]\n",
    "\n",
    "for model in models:\n",
    "    m = model['name']\n",
    "    dd['bet_{}'.format(m)] = 0.\n",
    "    dd['profit_{}'.format(m)] = 0.\n",
    "    dd['n_{}'.format(m)] = 0.\n",
    "    dd['n_odds_{}'.format(m)] = 0.\n",
    "    dd['pred_{}_std'.format(m)] = 0.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['pred_rnd_1'] = np.random.rand(dd.shape[0])\n",
    "dd['maj_1'] = 0.\n",
    "dd['pred_maj_1'] = 0.\n",
    "dd['stacked_maj_1'] = 0.\n",
    "dd['pred_stacked_maj_1'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model[\"name\"] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_bet(r):\n",
    "    for model in models:\n",
    "        asc = not model['name'].startswith('stacked')\n",
    "        p = 'pred_{}_1'.format(model['name'])\n",
    "        #print(model['name'], df['pred_{}_1'.format(model['name'])].mean())\n",
    "        s = r.sort_values(by=p, ascending=asc)\n",
    "        o = s.index.sort_values(ascending=True, return_indexer=True)\n",
    "        s2 = r.sort_values(by='final_odds_ref')\n",
    "        o2 = s2.index.sort_values(ascending=True, return_indexer=True)\n",
    "\n",
    "\n",
    "        idx = (r[p] == r[p].max())\n",
    "\n",
    "        r['bet_{}'.format(model['name'])] = np.clip(r[p], a_min=0., a_max=1.) #((idx).astype('float'))\n",
    "\n",
    "\n",
    "        r['n_{}'.format(model['name'])] = o[1]\n",
    "        r['n_odds_{}'.format(model['name'])] = o2[1]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dd.groupby('race_id').apply(fast_bet)\n",
    "\n",
    "for model in models:\n",
    "    dd['profit_{}'.format(model['name'])] = dd['bet_{}'.format(model['name'])] * 1.0 * (dd['target_returns']-1.0)\n",
    "\n",
    "cols = ['profit_{}'.format(model['name']) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mm = [m['name'] for m in models if m['name'].startswith('nn_') or m['name'].startswith('knn_') or m['name'].startswith('xgb_')]\n",
    "\n",
    "dd['n_maj'] = dd[['n_{}'.format(m) for m in mm]].sum(axis=1)\n",
    "dd['n_maj'] /= dd['declared_player_count']\n",
    "dd['n_maj'] = dd['n_maj'].round(1)\n",
    "dd['pred_maj_1'] = dd['n_maj']\n",
    "\n",
    "mm = [m['name'] for m in models if m['name'].startswith('stacked_stacked')]\n",
    "\n",
    "dd['n_stacked_maj'] = dd[['n_{}'.format(m) for m in mm]].sum(axis=1)\n",
    "dd['n_stacked_maj'] /= dd['declared_player_count']\n",
    "dd['n_stacked_maj'] = dd['n_stacked_maj'].round(1)\n",
    "dd['pred_stacked_maj_1'] = dd['n_stacked_maj']\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    m = model['name']\n",
    "    #dd['profit_{}'.format(m)] = np.clip(dd['pred_{}_1'.format(m)], a_min=0., a_max=10.) * 1.0 * (dd['target_returns']-1.0)\n",
    "    #dd['profit_{}'.format(m)] = 1.0 * (dd['target_returns']-1.0)\n",
    "    dd['bet_{}'.format(m)] = 1#np.ceil(0.1 * np.clip((df['pred_{}_1'.format(m)]), a_min=0., a_max=10.) * np.log(df['n_odds_{}'.format(m)]+1.) )\n",
    "    dd['profit_{}'.format(m)] = dd['bet_{}'.format(m)] * 1.0 * (dd['target_returns']-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "            'position', \n",
    "            'n_maj',\n",
    "            'n_stacked_maj',\n",
    "            'declared_player_count', \n",
    "            'sub_category', \n",
    "            'num', \n",
    "            'final_odds', \n",
    "            'final_odds_ref', \n",
    "            'final_odds_ref_unibet', \n",
    "            'target',\n",
    "            'target_stacked',\n",
    "            'race_winner_dividend',\n",
    "            'trueskill_mu',\n",
    "        ] + [\n",
    "            'n_{}'.format(model['name']) for model in models\n",
    "        ] + [\n",
    "            'pred_{}_1'.format(model['name']) for model in models\n",
    "        ] + [\n",
    "            'bet_{}'.format(model['name']) for model in models\n",
    "        ] + [\n",
    "            'profit_{}'.format(model['name']) for model in models\n",
    "        ]\n",
    "exploration.random_race(dd, \n",
    "                        cols=cols\n",
    "                       ).sort_values(by='position', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = dd.groupby('race_id')['final_odds_offline'].std()\n",
    "#s = s.to_frame()\n",
    "#s.columns = ['final_odds_offline_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dd = dd.join(s, how='left', on='race_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dd['prize'].apply(np.exp).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models: \n",
    "    print(m['name'])\n",
    "    print(dd['pred_{}_1'.format(m['name'])].quantile(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = 'category'\n",
    "for s in dd[f].value_counts().index:\n",
    "    r = pd.DataFrame(columns=['r', 'bets_mean', 'bets_max', 'bets_min', 'profit_mean', 'profit_max', 'profit_min', 'stash_min', 'stash_max', 'count'], index=[model['name'] for model in models])\n",
    "    print(s)\n",
    "    for model in models:\n",
    "        \n",
    "        m = model['name']\n",
    "        #if not m.startswith('stacked'):\n",
    "        #    continue\n",
    "\n",
    "        #for c in dd['sub_category'].value_counts().sort_values(ascending=False).index[0:7]:\n",
    "        #print(c)\n",
    "\n",
    "        ddd = dd[dd[f]==s]#dd[(dd['category'].isin(['PLAT'])) & (dd['sub_category'].isin(['HANDICAP'])) ]#dd[(dd['sub_category']==c)]# & (dd['sub_category'].isin(['HANDICAjP_DIVISE', 'HANjDICAP', 'AUTOSTART'])) ]\n",
    "        #ddd = ddd.groupby('race_id').filter(lambda r: r['pred_{}_1'.format(m)].std() > 0.01)\n",
    "        #g = ddd[(ddd['n_odds_{}'.format(m)]>=0) & (ddd['pred_{}_1'.format(m)] >= np.quantile(ddd['pred_{}_1'.format(m)], 0.7)) & (ddd['final_odds_ref_offline'].notnull()) & (ddd['final_odds_ref_offline'] > ddd['final_odds_offline']) & (ddd['final_odds_ref'] > 20) & (ddd['final_odds_ref']<50)][['start_at', 'race_id', 'position', 'final_odds', 'final_odds_ref', 'final_odds_ref_unibet', 'final_odds_ref_offline_std', 'final_odds_offline_std', 'profit_{}'.format(m), 'bet_{}'.format(m), 'pred_{}_1'.format(m)]].copy()\n",
    "        #(ddd['final_odds_ref_offline'] > ddd['final_odds_offline']) \n",
    "        g = ddd[  (ddd['final_odds_ref_offline'] > ddd['final_odds_offline'])  & (ddd['n_{}'.format(m)]<=0) & (ddd['final_odds_ref'] > 20) & (ddd['final_odds_ref']<50) & (ddd['final_odds_ref_offline'].notnull())  ][['start_at', 'race_id', 'position', 'final_odds', 'final_odds_ref', 'profit_{}'.format(m), 'bet_{}'.format(m), 'pred_{}_1'.format(m)]].copy()\n",
    "        #g = ddd[(ddd['n_{}'.format(m)]==0)].copy()\n",
    "        g['stash_{}'.format(m)] = g['profit_{}'.format(m)].cumsum()\n",
    "        g['bets_{}'.format(m)] = g['bet_{}'.format(m)].cumsum()\n",
    "        g['stash_{}'.format(m)].plot(figsize=(16, 4), title=m)\n",
    "        g['bets_{}'.format(m)].plot()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        #print(m, np.quantile(ddd['pred_{}_1'.format(m)], 0.7), ddd['start_at'].min(), ddd['start_at'].max())\n",
    "\n",
    "        r.loc[m]['r'] = g['profit_{}'.format(m)].sum() / g['bet_{}'.format(m)].sum()\n",
    "        r.loc[m]['bets_mean'] = g['bet_{}'.format(m)].mean()\n",
    "        r.loc[m]['bets_min'] = g['bet_{}'.format(m)].min()\n",
    "        r.loc[m]['bets_max'] = g['bet_{}'.format(m)].max()\n",
    "        r.loc[m]['profit_mean'] = g['profit_{}'.format(m)].mean()\n",
    "        r.loc[m]['profit_min'] = g['profit_{}'.format(m)].min()\n",
    "        r.loc[m]['profit_max'] = g['profit_{}'.format(m)].max()\n",
    "        r.loc[m]['stash_min'] = g['stash_{}'.format(m)].min()\n",
    "        r.loc[m]['stash_max'] = g['stash_{}'.format(m)].max()\n",
    "        r.loc[m]['count'] = g['stash_{}'.format(m)].count()\n",
    "\n",
    "    print(r[['r', 'count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bet(df):\n",
    "    models = [{\"name\":'mlp_30'}]\n",
    "    \n",
    "    def fast_bet(r):\n",
    "        for model in models:\n",
    "            p = 'pred_{}_1'.format(model['name'])\n",
    "            #print(model['name'], df['pred_{}_1'.format(model['name'])].mean())\n",
    "            s = r.sort_values(by=p)\n",
    "            o = s.index.sort_values(ascending=True, return_indexer=True)\n",
    "            s2 = r.sort_values(by='final_odds_ref')\n",
    "            o2 = s2.index.sort_values(ascending=True, return_indexer=True)\n",
    "\n",
    "\n",
    "            idx = (r[p] == r[p].max())\n",
    "        #idx = (r['pred_knn_5_1'] > 0) & (r['final_odds_ref'] > 5)\n",
    "        #idx = (r['pred_knn_5_1'] > 0.) & (r['final_odds_ref'] > 5) & (r['final_odds_ref'] < 30)\n",
    "            #if r[p].std() == 0:\n",
    "            #    r['bet'] = 0\n",
    "            #    return r\n",
    "            r['bet_{}'.format(model['name'])] = np.clip(r[p], a_min=0., a_max=1.) #((idx).astype('float'))\n",
    "\n",
    "\n",
    "            r['n_{}'.format(model['name'])] = o[1]\n",
    "            r['n_odds_{}'.format(model['name'])] = o2[1]\n",
    "        return r\n",
    "    \n",
    "    df = df[(df['country']=='FRA') & (df['sub_category'].isin(['HANDICAP', 'HANDICAP_DIVISE']))].copy()\n",
    "    df = df.groupby('race_id').apply(fast_bet)\n",
    "\n",
    "    for model in models:\n",
    "        m = model['name']\n",
    "        #dd['profit_{}'.format(m)] = np.clip(dd['pred_{}_1'.format(m)], a_min=0., a_max=10.) * 1.0 * (dd['target_returns']-1.0)\n",
    "        #dd['profit_{}'.format(m)] = 1.0 * (dd['target_returns']-1.0)\n",
    "        df['bet_{}'.format(m)] = np.ceil(0.1 * np.clip((df['pred_{}_1'.format(m)]/10.), a_min=0., a_max=10.) * np.log(df['n_odds_{}'.format(m)]+1.) )\n",
    "        df['profit_{}'.format(m)] = df['bet_{}'.format(m)] * 1.0 * (df['target_returns']-1.0)\n",
    "\n",
    "    df['bet'] = df[['bet_{}'.format(model['name']) for model in models]].sum(axis=1)\n",
    "    df['profit'] = df[['profit_{}'.format(model['name']) for model in models]].sum(axis=1)\n",
    "    df['target'] = 'mlp_30_1'\n",
    "    \n",
    "    bets = df[(df['pred_mlp_30_1'] >= 13.6) & (df['final_odds_ref_offline']>df['final_odds_offline']) & (df['final_odds_ref'] > 20) & (df['final_odds_ref']<50)][['race_id', 'start_at', 'bet', 'category', 'sub_category', 'country', 'target', 'profit', 'num', 'race_id', 'position', 'final_odds_ref', 'final_odds', 'profit_{}'.format(m), 'bet_{}'.format(m), 'pred_{}_1'.format(m)]].copy()\n",
    "    bets['date'] = pd.to_datetime(bets['start_at'])\n",
    "    \n",
    "    #bets = bets.set_index(bets['date'])\n",
    "    #bets = bets.sort_index()\n",
    "    \n",
    "    bets['bets'] = bets['bet'].cumsum()\n",
    "    bets['stash'] = bets['profit'].cumsum()\n",
    "\n",
    "    return bets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bets = bet(df, program.model.features, program.model.categorical_features, \n",
    "#    N=1, max_odds=30, break_on_bet=True, break_on_odds=False, \n",
    "#    targets=['pred_rnd_1', 'final_odds_ref', 'pred_sum_1'] + ['pred_{}_{}'.format(model['name'], i+1) for i in range(program.model.params['n_targets']) for model in program.model.models]# + ['pred_stacked_{}_1'.format(model['name']) for model in program.model.stacked_models] \n",
    "#   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets = bet(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bets = bets.set_index(bets['date'])\n",
    "#bets = bets.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets['target'] = 'fg'\n",
    "list(bets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_bb(bb, f):\n",
    "    results = []\n",
    "\n",
    "    for s in bb[f].value_counts().index:\n",
    "        results = []\n",
    "        x = bb[ (bb[f] == s)  ].copy()\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "        #print(\"---\\n{}\\t{:+.2f}\\t{:+.2f}\\t{:+.2f}\\n---\".format(s, x['profit'].sum(), x['bet'].sum(), len(x)))\n",
    "\n",
    "        fig, axs = plt.subplots(1,1)\n",
    "\n",
    "        for t in x['target'].value_counts().index:\n",
    "            bbb = x[(x['target'] == t)].copy()\n",
    "            #bbb = bbb[ (bbb['pred']>bbb['pred'].quantile(0.85)) ].copy()\n",
    "            \n",
    "            if 'profit_placed' not in list(bbb.columns):\n",
    "                bbb['profit_placed'] = 0\n",
    "\n",
    "            results.append({\n",
    "                'idx_1': s,\n",
    "                'idx_2': t,\n",
    "                'profit': bbb.profit.sum(),\n",
    "                'profit_place': bbb.profit_placed.sum(),\n",
    "                'bet': bbb.bet.sum(),\n",
    "                'bets': bbb.bet.count(),\n",
    "                'avg': bbb.profit.sum() / bbb.bet.sum()\n",
    "            })\n",
    "\n",
    "            '''\n",
    "            bbb['stash'] = bbb['profit'].cumsum()\n",
    "            bbb['cbet'] = bbb['bet'].cumsum()\n",
    "\n",
    "            fig, axs = plt.subplots(1,1)\n",
    "            bbb['stash'].plot(figsize=(6, 2))\n",
    "            bbb['cbet'].plot(figsize=(6, 2))\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            #print(\"{:10s}: \\t {:+.2f} \\t {:+.0f} \\t {:+.2f}\".format(t, bbb.profit.sum(), bbb.profit.count(), bbb.profit.mean()) )\n",
    "\n",
    "            bbb['stash'] = bbb['profit'].cumsum()\n",
    "            bbb['cbet'] = bbb['bet'].cumsum()\n",
    "\n",
    "            bbb['stash'].plot(figsize=(10, 2))\n",
    "            #bbb['cbet'].plot(figsize=(10, 2))\n",
    "\n",
    "        results = pd.DataFrame(results)\n",
    "        results = results.set_index(['idx_1', 'idx_2'])\n",
    "        print(results.sort_values(by='avg', ascending=False))\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_bb(bets, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries = list(bets['country'].value_counts()[0:10].index)\n",
    "#sub_categories = list(bets['sub_category'].value_counts()[0:10].index)\n",
    "\n",
    "#%store countries\n",
    "#%store sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "target = 'pred_knn_1_1'\n",
    "\n",
    "c_min = bets[(bets['target'] == target)]['pred'].min()\n",
    "c_mean = bets[(bets['target'] == target)]['pred'].mean()\n",
    "c_max = bets[(bets['target'] == target)]['pred'].max()\n",
    "\n",
    "space = [\n",
    "          Real(1, 10, name='min_odds'),\n",
    "          Real(10, 60, name='max_odds'),\n",
    "          Real(c_min, c_mean, name='min_pred'),\n",
    "          Real(c_mean, c_max, name='max_pred'),\n",
    "          Integer(5, 25, name='max_players')] + [\n",
    "          Integer(0,1, name='country_{}'.format(country)) for country in countries] + [\n",
    "          Integer(0,1, name='sub_category_{}'.format(sub_category)) for sub_category in sub_categories] + [\n",
    "          Integer(0,1, name='nb_{}'.format(n)) for n in range(0,6)]\n",
    "         \n",
    "def x_to_params(x):\n",
    "    params = {}\n",
    "    \n",
    "    params['min_odds'] = x[0]\n",
    "    params['max_odds'] = x[1]\n",
    "    params['max_pred'] = x[3]\n",
    "    params['min_pred'] = x[2]\n",
    "    params['max_players'] = x[4]\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        params['country_{}'.format(country)] = x[5+i]\n",
    "        \n",
    "    for i, sc in enumerate(sub_categories):\n",
    "        params['sub_category_{}'.format(sc)] = x[5+len(countries)+i]\n",
    "        \n",
    "    for n in range(0,6):\n",
    "        params['nb_{}'.format(n)] = x[5+len(countries)+len(sub_categories)+n]\n",
    "\n",
    "    return params\n",
    "\n",
    "@use_named_args(space)\n",
    "def f(**params):\n",
    "    return ff(params)\n",
    "    \n",
    "def ff(params, train=True):\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    b = bets[ (bets['pred'] != 0) & (bets['target']==target) & (bets['pred_std'] != 0)]\n",
    "    \n",
    "    b = b[ (b['odds_ref'] > params['min_odds']) & (b['odds_ref'] < params['max_odds']) & (b['declared_player_count'] > 1) & (b['declared_player_count'] <= params['max_players']) ]\n",
    "    \n",
    "    #b = b[(b['pred'] >= params['min_pred']) & (b['pred'] <= params['max_pred'])]\n",
    "    \n",
    "    for country in countries:\n",
    "        if params['country_{}'.format(country)] == 0:\n",
    "            b = b[ b['country'] != country ]\n",
    "            \n",
    "    for sub_category in sub_categories:\n",
    "        if params['sub_category_{}'.format(sub_category)] == 0:\n",
    "            b = b[ b['sub_category'] != sub_category ]\n",
    "            \n",
    "    for n in range(0,6):\n",
    "        if params['nb_{}'.format(n)] == 0:\n",
    "            b = b[ b['nb'] != n]\n",
    "    \n",
    "    p = b.profit.sum()\n",
    "    pp = len(b[b['profit'] > 0])\n",
    "    bet = b.bet.sum()\n",
    "    \n",
    "    print(\"{:+.2f} {:+.2f}\\n\".format(p, bet))\n",
    "        \n",
    "    if bet == 0:\n",
    "        return 0\n",
    "    \n",
    "    if not train:\n",
    "        return b\n",
    "    \n",
    "    return - (p)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_mean, c_min, c_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from skopt import dummy_minimize, gp_minimize, gbrt_minimize\n",
    "\n",
    "#res = dummy_minimize(f, space, n_calls=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_to_params(res.x), res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = x_to_params(res.x)\n",
    "#%store params\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store -r params\n",
    "#%store -r countries\n",
    "#%store -r sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb = ff(params, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb = bets[(bets['pred'] > 1.) & (bets['next_pred_1'] != bets['next_pred_2'])]\n",
    "#bb = bets[(bets['pred_std'] < 0.1) & (bets['pred'] < 1.)]\n",
    "#bb = bets[ (bets['odds_ref'] > 1) & (bets['odds_ref'] < 30) & (bets['pred'] > 1) & (bets['target'] == 'pred_xgb_100_1') ]\n",
    "#graph_bb( bb[bb['target']=='pred_knn_1_1'], 'category')\n",
    "#graph_bb( bets, 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets = bets.iloc[:,~bets.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb = bets[(bets['sub_category']=='HANDICAP') & (bets['country'] != 'FRA')]\n",
    "#bb = bb[(bb['pred_mlp_10_1']>118) & (bb['final_odds_ref']>=bb['final_odds'])].copy()\n",
    "bb = bets\n",
    "bb['stash'] = bb.profit.cumsum()\n",
    "bb['stash'].plot(figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the program when the model looks good, call: program.lock('2020-03-03')\n",
    "\n",
    "# a copy of the program, model and dataset class will be created\n",
    "\n",
    "# after this, open the new program class in *ml/pipeline/programs* and update the `model_params` in the `run` function\n",
    "\n",
    "# add any additional bet filter and bet strategy to the program bet function\n",
    "\n",
    "# add the new program to the better command *pmu/management/commands/bet.py*: programs = ['2020-03-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program.lock('position_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
